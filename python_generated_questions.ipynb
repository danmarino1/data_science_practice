{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of your code should be the original DataFrame, but with missing values in the 'Revenue' column filled in as described, a new 'Rating Category' column, and the mean revenue for each 'Rating Category'. The mean revenue should be output as a pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies_df = pd.read_clipboard(sep=',')\n",
    "#movies_df.to_csv(\"movies_sample.csv\", index=False)\n",
    "movies_df = pd.read_csv(\"movies_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_revenue = movies_df['Revenue'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.Revenue.fillna(median_revenue, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Year</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Rating Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>Action</td>\n",
       "      <td>2015</td>\n",
       "      <td>124</td>\n",
       "      <td>7.0</td>\n",
       "      <td>652.27</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manchester by the Sea</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2016</td>\n",
       "      <td>137</td>\n",
       "      <td>7.9</td>\n",
       "      <td>47.70</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Circle</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>2017</td>\n",
       "      <td>110</td>\n",
       "      <td>5.3</td>\n",
       "      <td>20.48</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Avengers</td>\n",
       "      <td>Action</td>\n",
       "      <td>2012</td>\n",
       "      <td>143</td>\n",
       "      <td>8.1</td>\n",
       "      <td>623.28</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>Animation</td>\n",
       "      <td>2010</td>\n",
       "      <td>103</td>\n",
       "      <td>8.3</td>\n",
       "      <td>414.98</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>John Wick</td>\n",
       "      <td>Action</td>\n",
       "      <td>2014</td>\n",
       "      <td>101</td>\n",
       "      <td>7.2</td>\n",
       "      <td>43.00</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Shape of Water</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>2017</td>\n",
       "      <td>123</td>\n",
       "      <td>7.4</td>\n",
       "      <td>63.86</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inside Out</td>\n",
       "      <td>Animation</td>\n",
       "      <td>2015</td>\n",
       "      <td>95</td>\n",
       "      <td>8.2</td>\n",
       "      <td>356.45</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Frozen</td>\n",
       "      <td>Animation</td>\n",
       "      <td>2013</td>\n",
       "      <td>102</td>\n",
       "      <td>7.5</td>\n",
       "      <td>400.74</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Title      Genre  Year  Runtime  Rating  Revenue   \n",
       "0         Jurassic World     Action  2015      124     7.0   652.27  \\\n",
       "1  Manchester by the Sea      Drama  2016      137     7.9    47.70   \n",
       "2             The Circle   Thriller  2017      110     5.3    20.48   \n",
       "3           The Avengers     Action  2012      143     8.1   623.28   \n",
       "4            Toy Story 3  Animation  2010      103     8.3   414.98   \n",
       "5              John Wick     Action  2014      101     7.2    43.00   \n",
       "6     The Shape of Water    Fantasy  2017      123     7.4    63.86   \n",
       "7             Inside Out  Animation  2015       95     8.2   356.45   \n",
       "8                 Frozen  Animation  2013      102     7.5   400.74   \n",
       "\n",
       "  Rating Category  \n",
       "0       Very Good  \n",
       "1       Very Good  \n",
       "2         Average  \n",
       "3       Very Good  \n",
       "4       Very Good  \n",
       "5       Very Good  \n",
       "6       Very Good  \n",
       "7       Very Good  \n",
       "8       Very Good  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rate_films(x):\n",
    "    if x >= 8.5:\n",
    "        return \"Excellent\"\n",
    "    elif x >= 7:\n",
    "        return \"Very Good\"\n",
    "    elif x >= 5.5:\n",
    "        return \"Good\"\n",
    "    else:\n",
    "        return \"Average\"\n",
    "\n",
    "\n",
    "movies_df[\"Rating Category\"] = movies_df[\"Rating\"].apply(rate_films)\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating Category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>20.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Good</th>\n",
       "      <td>325.285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Revenue\n",
       "Rating Category         \n",
       "Average           20.480\n",
       "Very Good        325.285"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.groupby(\"Rating Category\")[['Revenue']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert The Circle to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1490\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49m_cython_operation(\n\u001b[1;32m   1491\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39maggregate\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1492\u001b[0m         values,\n\u001b[1;32m   1493\u001b[0m         how,\n\u001b[1;32m   1494\u001b[0m         axis\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mndim \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1495\u001b[0m         min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m   1496\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1497\u001b[0m     )\n\u001b[1;32m   1498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1499\u001b[0m     \u001b[39m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m     \u001b[39m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m     \u001b[39m# try to python agg\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m     \u001b[39m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m ngroups \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngroups\n\u001b[0;32m--> 959\u001b[0m \u001b[39mreturn\u001b[39;00m cy_op\u001b[39m.\u001b[39;49mcython_operation(\n\u001b[1;32m    960\u001b[0m     values\u001b[39m=\u001b[39;49mvalues,\n\u001b[1;32m    961\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    962\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m    963\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    964\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[1;32m    965\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    966\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[1;32m    650\u001b[0m         values,\n\u001b[1;32m    651\u001b[0m         min_count\u001b[39m=\u001b[39mmin_count,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    655\u001b[0m     )\n\u001b[0;32m--> 657\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_op_ndim_compat(\n\u001b[1;32m    658\u001b[0m     values,\n\u001b[1;32m    659\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m    660\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[1;32m    661\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mcomp_ids,\n\u001b[1;32m    662\u001b[0m     mask\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    663\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    664\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:497\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mT\n\u001b[0;32m--> 497\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_cython_op(\n\u001b[1;32m    498\u001b[0m     values,\n\u001b[1;32m    499\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m    500\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[1;32m    501\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mcomp_ids,\n\u001b[1;32m    502\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[1;32m    503\u001b[0m     result_mask\u001b[39m=\u001b[39;49mresult_mask,\n\u001b[1;32m    504\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    505\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m out_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[0;32m--> 541\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cython_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkind, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow, values\u001b[39m.\u001b[39;49mdtype, is_numeric)\n\u001b[1;32m    542\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[0;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39m__signatures__:\n\u001b[1;32m    172\u001b[0m     \u001b[39m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    174\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfunction is not implemented for this dtype: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[how->\u001b[39m\u001b[39m{\u001b[39;00mhow\u001b[39m}\u001b[39;00m\u001b[39m,dtype->\u001b[39m\u001b[39m{\u001b[39;00mdtype_str\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1692\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(x)\n\u001b[1;32m   1693\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1694\u001b[0m     \u001b[39m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'The Circle'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1696\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39;49m(x)\n\u001b[1;32m   1697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1698\u001b[0m     \u001b[39m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m movies_df[\u001b[39m'\u001b[39m\u001b[39mRevenue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m movies_df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mDecade\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGenre\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39m'\u001b[39m\u001b[39mRevenue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtransform(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mfillna(x\u001b[39m.\u001b[39mmedian()))\n\u001b[1;32m      5\u001b[0m movies_df[\u001b[39m'\u001b[39m\u001b[39mRating Category\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mcut(movies_df[\u001b[39m'\u001b[39m\u001b[39mRating\u001b[39m\u001b[39m'\u001b[39m], bins\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m,\u001b[39m5.5\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m8.5\u001b[39m,\u001b[39m10\u001b[39m], labels\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mAverage\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mGood\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mVery Good\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mExcellent\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m mean_revenue \u001b[39m=\u001b[39m movies_df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mRating Category\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mmean()[\u001b[39m'\u001b[39m\u001b[39mRevenue\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   1854\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1855\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_agg_general(\n\u001b[1;32m   1856\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1857\u001b[0m         alt\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only),\n\u001b[1;32m   1858\u001b[0m         numeric_only\u001b[39m=\u001b[39;49mnumeric_only,\n\u001b[1;32m   1859\u001b[0m     )\n\u001b[1;32m   1860\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_py_fallback(values, ndim\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mndim, alt\u001b[39m=\u001b[39malt)\n\u001b[1;32m   1505\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> 1507\u001b[0m new_mgr \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mgrouped_reduce(array_func)\n\u001b[1;32m   1508\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   1509\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:1503\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[39mif\u001b[39;00m blk\u001b[39m.\u001b[39mis_object:\n\u001b[1;32m   1500\u001b[0m     \u001b[39m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m     \u001b[39m#  while others do not.\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m     \u001b[39mfor\u001b[39;00m sb \u001b[39min\u001b[39;00m blk\u001b[39m.\u001b[39m_split():\n\u001b[0;32m-> 1503\u001b[0m         applied \u001b[39m=\u001b[39m sb\u001b[39m.\u001b[39;49mapply(func)\n\u001b[1;32m   1504\u001b[0m         result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1505\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m    324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[1;32m    325\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[39m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[39m    one\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1490\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39m_cython_operation(\n\u001b[1;32m   1491\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1492\u001b[0m         values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1497\u001b[0m     )\n\u001b[1;32m   1498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1499\u001b[0m     \u001b[39m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m     \u001b[39m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m     \u001b[39m# try to python agg\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m     \u001b[39m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[0;32m-> 1503\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_agg_py_fallback(values, ndim\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mndim, alt\u001b[39m=\u001b[39;49malt)\n\u001b[1;32m   1505\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     ser \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m   1454\u001b[0m \u001b[39m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[1;32m   1455\u001b[0m \u001b[39m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \u001b[39m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[0;32m-> 1457\u001b[0m res_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49magg_series(ser, alt, preserve_dtype\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(values, Categorical):\n\u001b[1;32m   1460\u001b[0m     \u001b[39m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m     \u001b[39m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m     \u001b[39m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m     res_values \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(values)\u001b[39m.\u001b[39m_from_sequence(res_values, dtype\u001b[39m=\u001b[39mvalues\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39m_values, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    988\u001b[0m     \u001b[39m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[39m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[39m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[39m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m    996\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    997\u001b[0m \u001b[39mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1012\u001b[0m splitter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_splitter(obj, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   1014\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[0;32m-> 1015\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[1;32m   1016\u001b[0m     res \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mextract_result(res)\n\u001b[1;32m   1018\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m initialized:\n\u001b[1;32m   1019\u001b[0m         \u001b[39m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   1854\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1855\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   1856\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m-> 1857\u001b[0m         alt\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only),\n\u001b[1;32m   1858\u001b[0m         numeric_only\u001b[39m=\u001b[39mnumeric_only,\n\u001b[1;32m   1859\u001b[0m     )\n\u001b[1;32m   1860\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11539\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m  11540\u001b[0m     _num_doc,\n\u001b[1;32m  11541\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the mean of the values over the requested axis.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11554\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11555\u001b[0m ):\n\u001b[0;32m> 11556\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mmean(\u001b[39mself\u001b[39;49m, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[1;32m  11195\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  11196\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11199\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11200\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m> 11201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function(\n\u001b[1;32m  11202\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanmean, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11203\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11154\u001b[0m     nv\u001b[39m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[39m=\u001b[39mname)\n\u001b[1;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m> 11158\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11159\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[1;32m  11160\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:4666\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4661\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   4662\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not allow \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mnumeric_only\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4663\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith non-numeric dtypes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4664\u001b[0m     )\n\u001b[1;32m   4665\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 4666\u001b[0m     \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    156\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[0;32m--> 421\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, mask\u001b[39m=\u001b[39;49mmask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    423\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[1;32m    424\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    724\u001b[0m     dtype_count \u001b[39m=\u001b[39m dtype\n\u001b[1;32m    726\u001b[0m count \u001b[39m=\u001b[39m _get_counts(values\u001b[39m.\u001b[39mshape, mask, axis, dtype\u001b[39m=\u001b[39mdtype_count)\n\u001b[0;32m--> 727\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum))\n\u001b[1;32m    729\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    730\u001b[0m     count \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1696\u001b[0m             x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39m(x)\n\u001b[1;32m   1697\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1698\u001b[0m             \u001b[39m# e.g. \"foo\"\u001b[39;00m\n\u001b[0;32m-> 1699\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not convert \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m to numeric\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert The Circle to numeric"
     ]
    }
   ],
   "source": [
    "### Generated solution\n",
    "import pandas as pd\n",
    "movies_df['Decade'] = movies_df['Year'].apply(lambda x: f\"{x//10*10}_{x//10*10+9}\")\n",
    "movies_df['Revenue'] = movies_df.groupby(['Decade', 'Genre'])['Revenue'].transform(lambda x: x.fillna(x.median()))\n",
    "movies_df['Rating Category'] = pd.cut(movies_df['Rating'], bins=[0,5.5,7,8.5,10], labels=['Average','Good','Very Good','Excellent'])\n",
    "mean_revenue = movies_df.groupby('Rating Category').mean()['Revenue']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the revenue null value fills, the generated answer makes a great point:\n",
    " - The expression {movies_df.groupby(['Decade', 'Genre'])['Revenue'].transform(lambda x: x.fillna(x.median()))} is an example of a more sophisticated method of data imputation, which takes into account the context of the missing data.\n",
    "\n",
    "- In this case, you're filling in missing 'Revenue' values with the median revenue of movies that are in the same genre and were released in the same decade. This makes sense because movies from the same genre and decade are more likely to have similar revenues compared to movies from a different genre or time period. This method provides a more accurate estimate of the missing values.\n",
    "\n",
    "- On the other hand, median_revenue = movies['Revenue'].median() calculates the median revenue across all movies, regardless of their genre or release date. If you were to fill in missing values with this median, you'd be ignoring the context in which the data is missing. For example, you'd be treating a drama movie from the 1980s the same as an action movie from the 2020s, even though these types of movies might have very different revenues.\n",
    "\n",
    "- Therefore, the first method is generally better because it's more likely to provide an accurate estimate of the missing data. However, the best method to use always depends on the specific dataset and problem at hand.\n",
    "\n",
    "for the rating category, I also learned a bunch.\n",
    "- movies_df['Rating Category'] = pd.cut(movies_df['Rating'], bins=[0,5.5,7,8.5,10], labels=['Average','Good','Very Good','Excellent'])\n",
    "- This line of code is using the pd.cut() function to create a new column in the DataFrame called 'Rating Category'. The pd.cut() function is a way to create categories (or \"bins\") based on numeric values. In this case, it's being used to categorize the 'Rating' column into different groups based on the rating score.\n",
    "\n",
    "- The bins argument is specifying the boundaries for each category. The list [0,5.5,7,8.5,10] means that the categories are:\n",
    "\n",
    "- This line of code is essentially mapping each movie's rating to a category. It's an example of \"binning\" or \"bucketing\", which are common techniques used in data analysis and machine learning to deal with continuous variables. In this case, it's being used to simplify the 'Rating' column and make it easier to analyze."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are given a list of dictionaries where each dictionary represents a movie. Each dictionary has the following key-value pairs:\n",
    "\n",
    "- 'Title': The title of the movie (string).\n",
    "- 'Genre': The genre of the movie (string).\n",
    "- 'Year': The year the movie was released (integer).\n",
    "- 'Runtime': The length of the movie in minutes (integer).\n",
    "- 'Rating': The average user rating out of 10 (float).\n",
    "Your task is to write a Python function that takes in this list and a genre, and returns the average rating of movies in that genre.\n",
    "\n",
    "In addition, write an SQL query that would perform the same operation on a table with the same columns.\n",
    "\n",
    "### Libraries Needed\n",
    "\n",
    "- Python: None\n",
    "- SQL: None (but you need to know SQL syntax)\n",
    "Inputs\n",
    "\n",
    "### The Python function average_rating_by_genre(movies: List[dict], genre: str) -> float: takes in two arguments:\n",
    "\n",
    "- movies: a list of dictionaries where each dictionary represents a movie with the key-value pairs described above.\n",
    "- genre: a string representing the genre of the movies for which you want to calculate the average rating.\n",
    "The SQL query should be written assuming you have a table named movies with the same columns as the dictionaries in the Python function.\n",
    "\n",
    "## Expected Outputs\n",
    "\n",
    "The Python function should return a float representing the average rating of movies in the input genre.\n",
    "\n",
    "The SQL query should return a single row with a single column (which you can call 'Average Rating') that represents the average rating of movies in the specified genre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [\n",
    "    {'Title': 'Jurassic World', 'Genre': 'Action', 'Year': 2015, 'Runtime': 124, 'Rating': 7.0},\n",
    "    {'Title': 'Inside Out', 'Genre': 'Animation', 'Year': 2015, 'Runtime': 95, 'Rating': 8.2},\n",
    "    {'Title': 'Toy Story 3', 'Genre': 'Animation', 'Year': 2010, 'Runtime': 103, 'Rating': 8.3},\n",
    "    {'Title': 'John Wick', 'Genre': 'Action', 'Year': 2014, 'Runtime': 101, 'Rating': 7.2},\n",
    "    {'Title': 'The Circle', 'Genre': 'Thriller', 'Year': 2017, 'Runtime': 110, 'Rating': 5.3},\n",
    "    {'Title': 'Manchester by the Sea', 'Genre': 'Drama', 'Year': 2016, 'Runtime': 137, 'Rating': 7.9},\n",
    "    {'Title': 'The Avengers', 'Genre': 'Action', 'Year': 2012, 'Runtime': 143, 'Rating': 8.1},\n",
    "    {'Title': 'Frozen', 'Genre': 'Animation', 'Year': 2013, 'Runtime': 102, 'Rating': 7.5},\n",
    "    {'Title': 'The Shape of Water', 'Genre': 'Fantasy', 'Year': 2017, 'Runtime': 123, 'Rating': 7.4},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_ratings=[]\n",
    "def average_by_genre(dictionary, genre):\n",
    "    for movie in dictionary:\n",
    "        if movie['Genre'] == genre:\n",
    "            genre_ratings.append(movie['Rating'])\n",
    "    return(round(sum(genre_ratings) / len(genre_ratings),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_by_genre(movies, 'Fantasy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in ['Action', 'Animation', 'Drama', 'Fantasy', 'Thriller']:\n",
    "    print(f\"The average rating of {genre} movies is {average_by_genre(movies, genre)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I did this in SQL on a table called Movies, I would use the following query:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    SELECT Genre, AVG(Rating) AS Avg_Rating, COUNT(*) AS Num_Ratings\n",
    "\n",
    "    FROM Movies\n",
    "\n",
    "    GROUP BY Genre\n",
    "\n",
    "    ORDER BY Avg_Rating DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are tasked with implementing a MovieDatabase class. The class should be initialized with a list of movies, where each movie is a dictionary with the following key-value pairs:\n",
    "\n",
    "- 'Title': The title of the movie (string).\n",
    "- 'Genre': The genre of the movie (string).\n",
    "- 'Year': The year the movie was released (integer).\n",
    "- 'Runtime': The length of the movie in minutes (integer).\n",
    "- 'Rating': The average user rating out of 10 (float).\n",
    "The MovieDatabase class should have a method average_rating_by_genre(self, genre: str) -> float: which returns the average rating of movies in the specified genre.\n",
    "\n",
    "### Libraries Needed\n",
    "\n",
    "- Python: None\n",
    "### Inputs\n",
    "\n",
    "The MovieDatabase class should be initialized with a movies: List[dict] argument, where movies is a list of dictionaries where each dictionary represents a movie with the key-value pairs described above.\n",
    "\n",
    "The average_rating_by_genre method should take in a single argument:\n",
    "\n",
    "- genre: a string representing the genre of the movies for which you want to calculate the average rating.\n",
    "Expected Outputs\n",
    "\n",
    "The average_rating_by_genre method should return a float representing the average rating of movies in the input genre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Movie:\n",
    "    def __init__(self, dictionary):\n",
    "        self.title = dictionary['Title']\n",
    "        self.genre = dictionary['Genre']\n",
    "        self.year = dictionary['Year']\n",
    "        self.runtime = dictionary['Runtime']\n",
    "        self.rating = dictionary['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie2 = Movie(movies[2])\n",
    "movie2.genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_as_objects = []\n",
    "\n",
    "for i in movies:\n",
    "    movies_as_objects.append(Movie(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_as_objects[0].rating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDatabase:\n",
    "    def __init__(self, movies: List[dict]):\n",
    "        self.movies = movies\n",
    "\n",
    "    def average_rating_by_genre(self, genre: str) -> float:\n",
    "        genre_movies = [movie for movie in self.movies if movie['Genre'] == genre]\n",
    "        average_rating = sum(movie['Rating'] for movie in genre_movies) / len(genre_movies)\n",
    "        return average_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took a different approach than what I ended up making, as it created a more comprehensive class that could be used to do more than just find the average rating by genre. I think this is a good approach. I also like how the class is initialized with a list of dictionaries, which is the same format as the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "You are given a small sample of a larger dataset, represented as a string that can be read into a pandas DataFrame using the `pd.read_clipboard()` function. The dataset represents sales data for a retail store and includes four columns: 'Product', 'Date', 'Sales', and 'Profit'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Your task is to:\n",
    "\n",
    "1. Read the data into a DataFrame.\n",
    "2. Convert the 'Date' column to datetime type.\n",
    "3. Replace any non-numeric characters in the 'Profit' column, then convert it to a numeric type.\n",
    "4. Calculate the total sales and profit for each product, and store the result in a new DataFrame.\n",
    "\n",
    "### Libraries Needed:\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "\n",
    "### Inputs:\n",
    "\n",
    "- A string representing the dataset.\n",
    "\n",
    "### Expected Outputs:\n",
    "\n",
    "- A DataFrame representing the cleaned dataset.\n",
    "- A DataFrame representing the total sales and profit for each product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading the data\n",
    "data = \"\"\"\n",
    "Product\tDate\tSales\tProfit\n",
    "Printer\t2022-05-17\t12\t$100\n",
    "Laptop\t2022-05-18\t10\t$150\n",
    "Printer\t2022-05-19\t8\t$75\n",
    "Monitor\t2022-05-20\t15\t$120\n",
    "Laptop\t2022-05-21\t7\t$100\n",
    "\"\"\"\n",
    "df = pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date = df.Date.astype('datetime64[ns]')\n",
    "\n",
    "df['Profit'] = df['Profit'].str.replace('$','').astype('int')\n",
    "df['Sales'] = df['Sales'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Sales: ${df.Sales.sum()}\")\n",
    "print(f\"Total Profit: ${df.Profit.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "Given a string of characters, write a function that calculates the frequency of each character in the string. Additionally, the function should return the character with the maximum frequency and the character with the minimum frequency.\n",
    "\n",
    "The function signature should be `def char_frequency(string: str) -> dict, str, str:`. The function should return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_characters(s):\n",
    "    split_string = s.split()\n",
    "    character_frequency = {}\n",
    "    for character in split_string:\n",
    "        if character in character_frequency:\n",
    "            character_frequency[character] += 1\n",
    "        else:\n",
    "            character_frequency[character] = 1\n",
    "    return character_frequency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_characters(\"I am learning data science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_characters(s):\n",
    "    split_string = s.split()\n",
    "    character_frequency = {}\n",
    "    for word in split_string:\n",
    "        for character in word:\n",
    "            if character in character_frequency:\n",
    "                character_frequency[character] += 1\n",
    "            else:\n",
    "                character_frequency[character] = 1\n",
    "    return character_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_characters(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_freqs = frequency_characters(\"Honolulu\")\n",
    "\n",
    "# get the most frequent character, the number of times it occurs, and any other characters that occur the same number of times\n",
    "max_freq = max(character_freqs.values())\n",
    "most_frequent_characters = [k for k, v in character_freqs.items() if v == max_freq]\n",
    "print(most_frequent_characters, max_freq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "You are given a list of dictionaries representing student grades for different subjects. Each dictionary includes the student's name and their grades for math, science, and english. Here's an example:\n",
    "```python\n",
    "grades = grades = [\n",
    "    {\"name\": \"Alice\", \"math\": 85, \"science\": 92, \"english\": 88},\n",
    "    {\"name\": \"Bob\", \"math\": 90, \"science\": 87, \"english\": 95},\n",
    "    {\"name\": \"Charlie\", \"math\": 82, \"science\": 89, \"english\": 91},\n",
    "    {\"name\": \"David\", \"math\": 78, \"science\": 76, \"english\": 84},\n",
    "    {\"name\": \"Eve\", \"math\": 92, \"science\": 90, \"english\": 93},\n",
    "    {\"name\": \"Frank\", \"math\": 89, \"science\": 92, \"english\": 87},\n",
    "    {\"name\": \"Grace\", \"math\": 91, \"science\": 88, \"english\": 93},\n",
    "    {\"name\": \"Henry\", \"math\": 86, \"science\": 85, \"english\": 90},\n",
    "    {\"name\": \"Ivy\", \"math\": 93, \"science\": 91, \"english\": 92},\n",
    "    {\"name\": \"Jack\", \"math\": 88, \"science\": 86, \"english\": 89},\n",
    "    {\"name\": \"Kate\", \"math\": 90, \"science\": 93, \"english\": 87},\n",
    "    {\"name\": \"Liam\", \"math\": 92, \"science\": 90, \"english\": 88},\n",
    "    {\"name\": \"Mia\", \"math\": 84, \"science\": 87, \"english\": 91},\n",
    "    {\"name\": \"Noah\", \"math\": 91, \"science\": 82, \"english\": 89},\n",
    "    {\"name\": \"Olivia\", \"math\": 89, \"science\": 88, \"english\": 90},\n",
    "    {\"name\": \"Patrick\", \"math\": 87, \"science\": 91, \"english\": 88},\n",
    "    {\"name\": \"Quinn\", \"math\": 86, \"science\": 90, \"english\": 87},\n",
    "    {\"name\": \"Ryan\", \"math\": 92, \"science\": 89, \"english\": 92},\n",
    "    {\"name\": \"Sara\", \"math\": 88, \"science\": 87, \"english\": 90},\n",
    "    {\"name\": \"Thomas\", \"math\": 90, \"science\": 88, \"english\": 89}\n",
    "]\n",
    "\n",
    "```\n",
    "#### Your task is to write a function that:\n",
    "\n",
    "Calculates the average grade for each student across all subjects, and adds this to the student's dictionary under the key \"average\".\n",
    "Returns a list of all students who have an average grade of 90 or higher. The list should contain only the names of the students, not their entire dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = grades = [\n",
    "    {\"name\": \"Alice\", \"math\": 85, \"science\": 92, \"english\": 88},\n",
    "    {\"name\": \"Bob\", \"math\": 90, \"science\": 87, \"english\": 95},\n",
    "    {\"name\": \"Charlie\", \"math\": 82, \"science\": 89, \"english\": 91},\n",
    "    {\"name\": \"David\", \"math\": 78, \"science\": 76, \"english\": 84},\n",
    "    {\"name\": \"Eve\", \"math\": 92, \"science\": 90, \"english\": 93},\n",
    "    {\"name\": \"Frank\", \"math\": 89, \"science\": 92, \"english\": 87},\n",
    "    {\"name\": \"Grace\", \"math\": 91, \"science\": 88, \"english\": 93},\n",
    "    {\"name\": \"Henry\", \"math\": 86, \"science\": 85, \"english\": 90},\n",
    "    {\"name\": \"Ivy\", \"math\": 93, \"science\": 91, \"english\": 92},\n",
    "    {\"name\": \"Jack\", \"math\": 88, \"science\": 86, \"english\": 89},\n",
    "    {\"name\": \"Kate\", \"math\": 90, \"science\": 93, \"english\": 87},\n",
    "    {\"name\": \"Liam\", \"math\": 92, \"science\": 90, \"english\": 88},\n",
    "    {\"name\": \"Mia\", \"math\": 84, \"science\": 87, \"english\": 91},\n",
    "    {\"name\": \"Noah\", \"math\": 91, \"science\": 82, \"english\": 89},\n",
    "    {\"name\": \"Olivia\", \"math\": 89, \"science\": 88, \"english\": 90},\n",
    "    {\"name\": \"Patrick\", \"math\": 87, \"science\": 91, \"english\": 88},\n",
    "    {\"name\": \"Quinn\", \"math\": 86, \"science\": 90, \"english\": 87},\n",
    "    {\"name\": \"Ryan\", \"math\": 92, \"science\": 89, \"english\": 92},\n",
    "    {\"name\": \"Sara\", \"math\": 88, \"science\": 87, \"english\": 90},\n",
    "    {\"name\": \"Thomas\", \"math\": 90, \"science\": 88, \"english\": 89}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_students(dataset):\n",
    "    studs = []\n",
    "    for student in dataset:\n",
    "        student['average'] = round((student['math'] + student['science'] + student['english']) / 3, 2)\n",
    "        if student['average'] > 90:\n",
    "            studs.append(student['name'])\n",
    "    return studs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_students = top_students(grades)\n",
    "top_students"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If I want to do this with Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student:\n",
    "    def __init__(self, name, math_grade, science_grade, english_grade):\n",
    "        self.name = name\n",
    "        self.math_grade = math_grade\n",
    "        self.science_grade = science_grade\n",
    "        self.english_grade = english_grade\n",
    "\n",
    "# Create instances of the Student class for the given students\n",
    "students = [\n",
    "    Student(\"Alice\", 85, 92, 88),\n",
    "    Student(\"Bob\", 90, 87, 95),\n",
    "    Student(\"Charlie\", 82, 89, 96),\n",
    "    Student(\"David\", 78, 76, 84),\n",
    "    Student(\"Eve\", 92, 90, 93)\n",
    "]\n",
    "\n",
    "# Add 20 additional students\n",
    "students.append(Student(\"Frank\", 89, 92, 87))\n",
    "students.append(Student(\"Grace\", 91, 88, 93))\n",
    "students.append(Student(\"Henry\", 86, 85, 90))\n",
    "students.append(Student(\"Ivy\", 93, 91, 92))\n",
    "students.append(Student(\"Jack\", 88, 86, 89))\n",
    "students.append(Student(\"Kate\", 90, 93, 87))\n",
    "students.append(Student(\"Liam\", 92, 90, 88))\n",
    "students.append(Student(\"Mia\", 84, 87, 91))\n",
    "students.append(Student(\"Noah\", 91, 82, 89))\n",
    "students.append(Student(\"Olivia\", 89, 88, 90))\n",
    "students.append(Student(\"Patrick\", 87, 91, 88))\n",
    "students.append(Student(\"Quinn\", 86, 90, 87))\n",
    "students.append(Student(\"Ryan\", 92, 89, 92))\n",
    "students.append(Student(\"Sara\", 88, 87, 90))\n",
    "students.append(Student(\"Thomas\", 90, 88, 89))\n",
    "\n",
    "# Print the list of students\n",
    "for student in students:\n",
    "    print(f\"Name: {student.name}, Math: {student.math_grade}, Science: {student.science_grade}, English: {student.english_grade}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_studs(students):\n",
    "    studs = []\n",
    "    for student in students:\n",
    "        # Use list comprehensions to find average grade across all subjects. append studs with names of students' whose average grade is greater than 90\n",
    "        if sum([student.math_grade, student.science_grade, student.english_grade]) / 3 > 90:\n",
    "            studs.append(student.name)\n",
    "    return studs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_studs(students)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a dataset that represents the scores of a series of data science quizzes. However, you suspect that some of these scores are incorrect due to system errors. You want to clean this data by removing the outliers using the Z-score method and then calculate some basic statistics about the cleaned data.\n",
    "\n",
    "Write a Python function that takes a Pandas DataFrame and a column name. The function should:\n",
    "\n",
    "1. Calculate the Z-score for each score in the specified column of the DataFrame.\n",
    "2. Consider scores to be outliers if their Z-scores are greater than 3 or less than -3.\n",
    "3. Remove the outliers from the DataFrame.\n",
    "4. Calculate and print the mean, median, and standard deviation of the cleaned scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_ids = ['q1', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9', 'q10', 'q11', 'q12']\n",
    "\n",
    "# Generate random scores between 0 and 100\n",
    "scores = np.random.uniform(0, 100, 88)\n",
    "\n",
    "# Create a DataFrame with 100 rows\n",
    "df = pd.DataFrame({'quiz_id': quiz_ids + ['q' + str(i) for i in range(13, 101)],\n",
    "                   'score': list(scores) + list(np.random.uniform(0, 100, 12))})\n",
    "\n",
    "# Display the extended DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores['z_score'] = (quiz_scores['score'] - quiz_scores['score'].mean()) / quiz_scores['score'].std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = (x - ) / \n",
    "\n",
    "\n",
    "<u>Where:</u>\n",
    "\n",
    "- z is the z-score\n",
    "- x is the observed value,\n",
    "-  is the mean of the population, and\n",
    "-  is the standard deviation of the population.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores['Outlier'] = False\n",
    "quiz_scores.loc[quiz_scores['z_score'].abs() > 3, 'score']['Outlier'] = True\n",
    "quiz_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores.loc[quiz_scores['Outlier'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores.drop(quiz_scores.loc[quiz_scores['Outlier'] == True].index, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No rows were outliers, but this is how it would be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores_mean = quiz_scores['score'].mean().round(2)\n",
    "quiz_scores_median = quiz_scores['score'].median().round(2)\n",
    "quiz_scores_std = quiz_scores['score'].std().round(2)\n",
    "\n",
    "print(f\"quiz score mean = {quiz_scores_mean}\")\n",
    "print(f\"quiz score median = {quiz_scores_median}\")\n",
    "print(f\"quiz score standard deviation = {quiz_scores_std}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "\n",
    "Imagine you have a database table named \"sales\" that stores sales data for an ecommerce company. The \"sales\" table has the following columns:\n",
    "\n",
    "- order_id (integer): A unique identifier for each order.\n",
    "- product_id (integer): A unique identifier for each product.\n",
    "- quantity (integer): The quantity of the product that was sold in the order.\n",
    "- sale_date (date): The date of the sale.\n",
    "\n",
    "Your task is to write a SQL query to fetch data that will be used to calculate the average quantity sold per product per month. \n",
    "\n",
    "Additionally, implement a function in Python using the sqlite3 library that takes the SQL query as a string and a sqlite3 connection object, executes the query, fetches the results, and then calculates and prints the average quantity sold per product per month based on the fetched data.\n",
    "\n",
    "# Libraries Needed: sqlite3, pandas\n",
    "\n",
    "# Inputs: \n",
    "\n",
    "- A string that contains the SQL query.\n",
    "- A sqlite3 connection object.\n",
    "\n",
    "Example in Python code:\n",
    "\n",
    "```python\n",
    "query = \"\"\"\n",
    "SELECT product_id, strftime('%Y-%m', sale_date) as month, SUM(quantity) as total_quantity\n",
    "FROM sales\n",
    "GROUP BY product_id, month\n",
    "\"\"\"\n",
    "\n",
    "def avg_quantity_per_product_per_month(query, conn):\n",
    "    # your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Outputs:\n",
    "\n",
    "Your function should print the average quantity sold per product per month. This can be done by grouping the fetched data by product and calculating the average quantity sold per month for each product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection object\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Define a DataFrame to populate the sales table\n",
    "data = {\n",
    "    'order_id': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'product_id': [101, 102, 103, 101, 102, 103, 101, 103],\n",
    "    'quantity': [2, 1, 3, 5, 2, 1, 4, 3],\n",
    "    'sale_date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-02-01', '2023-02-02', '2023-03-01', '2023-03-02', '2023-03-03']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the data to the sales table\n",
    "df.to_sql('sales', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT product_id, strftime('%Y-%m', sale_date) as month, SUM(quantity) as total_quantity\n",
    "FROM sales\n",
    "GROUP BY product_id, month\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run query on the database\n",
    "monthly_sales = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_quantity_per_product_per_month(query, conn):\n",
    "    monthly_sales = pd.read_sql(query, conn)\n",
    "    monthly_sales['avg_quantity'] = monthly_sales['total_quantity'].mean()\n",
    "    return monthly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better approach here is to use groupby\n",
    "\n",
    "def avg_quantity_per_product_per_month(query, conn):\n",
    "    dataframe = pd.read_sql(query, conn)\n",
    "    grouped_dataframe = dataframe.groupby(\"product_id\")\n",
    "    average_quantity = grouped_dataframe['total_quantity'].mean()\n",
    "    print(average_quantity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "\n",
    "You are working on a Natural Language Processing (NLP) project where you need to extract some features from text data. You have a list of sentences and you are interested in the number of digits that occur in each sentence.\n",
    "\n",
    "Write a Python function named `count_digits` that takes a list of strings (sentences) as input and returns a list of integers representing the number of digits in each sentence.\n",
    "\n",
    "# Libraries Needed: re (Regular expressions)\n",
    "\n",
    "# Inputs:\n",
    "\n",
    "A list of strings.\n",
    "\n",
    "Example in Python code:\n",
    "\n",
    "```python\n",
    "sentences = [\n",
    "    \"I have 2 dogs and 1 cat.\",\n",
    "    \"In 2022, the population of the world is estimated to be over 7.9 billion.\",\n",
    "    \"I was born on 12/12/2000.\"\n",
    "]\n",
    "\n",
    "counts = count_digits(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I have 2 dogs and 1 cat.\",\n",
    "    \"In 2022, the population of the world is estimated to be over 7.9 billion.\",\n",
    "    \"I was born on 12/12/2000.\",\n",
    "    \"In 1492, Columbus sailed the ocean blue.\",\n",
    "    \"The number 7 is considered lucky in many cultures.\",\n",
    "    \"There are 12 months, 52 weeks, and 365 days in a year.\",\n",
    "    \"Test without digits\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_digits(sentences):\n",
    "    sentences_counts = []\n",
    "    for sentence in sentences:\n",
    "        digit_counter = 0\n",
    "        for word in sentence.split():\n",
    "            for character in word:\n",
    "                if character.isdigit():\n",
    "                    digit_counter += 1\n",
    "        sentences_counts.append(digit_counter)\n",
    "    return sentences_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_digits(sentences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "\n",
    "You are provided with a dataset that includes stock prices for a particular company, and you are interested in visualizing the stock's closing price over time. \n",
    "\n",
    "The stock data is provided as a CSV string, where each row represents one day of trading. Each row includes the date, opening price, high price, low price, and closing price.\n",
    "\n",
    "Your task is to:\n",
    "1. Parse the CSV string into a pandas DataFrame.\n",
    "2. Convert the 'Date' column into a datetime data type.\n",
    "3. Set the 'Date' column as the index of the DataFrame.\n",
    "4. Plot a line graph of the closing prices over time.\n",
    "\n",
    "Here's the CSV data:\n",
    "\n",
    "```csv\n",
    "\"Date,Open,High,Low,Close\n",
    "2022-01-03,140.11,141.52,139.67,141.12\n",
    "2022-01-04,141.50,141.91,140.41,140.91\n",
    "2022-01-05,140.40,141.68,140.26,141.20\n",
    "2022-01-06,141.20,142.15,140.13,140.13\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = pd.read_clipboard(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick['Date'] = tick['Date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.line(tick, x='Date', y='Close', title='Stock Price')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "\n",
    "You are working as a Data Scientist at an e-commerce company and you have the historical transaction data for customers. The company wants to understand the behavior of the customers based on their purchasing frequency and amount spent.\n",
    "\n",
    "Given a dataset of transaction records, where each record includes a customer ID, transaction date, and transaction amount, you need to calculate the following for each customer:\n",
    "- The total amount spent,\n",
    "- The total number of transactions,\n",
    "- The average transaction amount,\n",
    "- The frequency of transactions (defined as the total number of transactions divided by the number of unique days on which transactions occurred).\n",
    "\n",
    "Finally, perform a k-means clustering (with k=3) on the calculated features to segment the customers.\n",
    "\n",
    "The input transaction data is provided as a CSV string as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Copy the entire CSV data (including headers) to your clipboard before running this code\n",
    "# Original CSV data\n",
    "data = \"\"\"Customer_ID,Transaction_Date,Transaction_Amount\n",
    "C001,2022-01-01,100.50\n",
    "C002,2022-01-01,200.00\n",
    "C001,2022-01-02,150.00\n",
    "C002,2022-01-03,300.00\n",
    "C001,2022-02-01,200.00\n",
    "C002,2022-02-01,150.00\n",
    "C001,2022-03-01,300.00\n",
    "C002,2022-03-02,400.00\n",
    "C001,2022-04-01,180.50\n",
    "C002,2022-04-02,250.00\n",
    "C003,2022-04-03,320.00\n",
    "C001,2022-05-01,210.00\n",
    "C002,2022-05-02,180.00\n",
    "C003,2022-05-03,370.00\n",
    "C001,2022-06-01,220.00\n",
    "C002,2022-06-02,190.00\n",
    "C003,2022-06-03,410.00\n",
    "C001,2022-07-01,230.00\n",
    "C002,2022-07-02,220.00\n",
    "C003,2022-07-03,450.00\n",
    "C001,2022-08-01,240.00\n",
    "C002,2022-08-02,210.00\n",
    "C003,2022-08-03,490.00\n",
    "C001,2022-09-01,250.00\n",
    "C002,2022-09-02,230.00\n",
    "C003,2022-09-03,530.00\n",
    "C001,2022-10-01,260.00\n",
    "C002,2022-10-02,250.00\n",
    "C003,2022-10-03,570.00\n",
    "C001,2022-11-01,270.00\n",
    "C002,2022-11-02,270.00\n",
    "C003,2022-11-03,610.00\n",
    "C001,2022-12-01,280.00\n",
    "C002,2022-12-02,290.00\n",
    "C003,2022-12-03,650.00\n",
    "C001,2023-01-01,290.00\n",
    "C002,2023-01-02,310.00\n",
    "C003,2023-01-03,690.00\n",
    "C001,2023-02-01,300.00\n",
    "C002,2023-02-02,330.00\n",
    "C003,2023-02-03,730.00\n",
    "C001,2023-03-01,310.00\n",
    "C002,2023-03-02,350.00\n",
    "C003,2023-03-03,770.00\n",
    "C001,2023-04-01,320.00\n",
    "C002,2023-04-02,370.00\n",
    "C003,2023-04-03,810.00\n",
    "C001,2023-05-01,330.00\n",
    "C002,2023-05-02,390.00\n",
    "C003,2023-05-03,850.00\n",
    "C001,2023-06-01,340.00\n",
    "C002,2023-06-02,410.00\n",
    "C003,2023-06-03,890.00\n",
    "C001,2023-07-01,350.00\n",
    "C002,2023-07-02,430.00\n",
    "C003,2023-07-03,930.00\n",
    "C001,2023-08-01,360.00\n",
    "C002,2023-08-02,450.00\n",
    "C003,2023-08-03,970.00\n",
    "C001,2023-09-01,370.00\n",
    "C002,2023-09-02,470.00\n",
    "C003,2023-09-03,1010.00\n",
    "C001,2023-10-01,380.00\n",
    "C002,2023-10-02,490.00\n",
    "C003,2023-10-03,1050.00\n",
    "C001,2023-11-01,390.00\n",
    "C002,2023-11-02,510.00\n",
    "C003,2023-11-03,1090.00\n",
    "C001,2023-12-01,400.00\n",
    "C002,2023-12-02,530.00\n",
    "C003,2023-12-03,1130.00\n",
    "\"\"\"\n",
    "\n",
    "# Additional data for new customers (C004 to C023)\n",
    "additional_data = \"\"\"\n",
    "C004,2022-01-01,120.50\n",
    "C005,2022-01-01,220.00\n",
    "C006,2022-01-02,130.00\n",
    "C004,2022-01-03,260.00\n",
    "C005,2022-02-01,240.00\n",
    "C006,2022-02-01,130.00\n",
    "C004,2022-03-01,330.00\n",
    "C005,2022-03-02,440.00\n",
    "C006,2022-04-01,280.50\n",
    "C007,2022-04-02,350.00\n",
    "C008,2022-04-03,420.00\n",
    "C004,2022-05-01,310.00\n",
    "C005,2022-05-02,280.00\n",
    "C006,2022-05-03,470.00\n",
    "C007,2022-06-01,320.00\n",
    "C008,2022-06-02,390.00\n",
    "C009,2022-06-03,510.00\n",
    "C004,2022-07-01,330.00\n",
    "C005,2022-07-02,320.00\n",
    "C006,2022-07-03,550.00\n",
    "C007,2022-08-01,340.00\n",
    "C008,2022-08-02,310.00\n",
    "C009,2022-08-03,590.00\n",
    "C010,2022-09-01,350.00\n",
    "C011,2022-09-02,430.00\n",
    "C012,2022-09-03,630.00\n",
    "C013,2022-10-01,360.00\n",
    "C014,2022-10-02,420.00\n",
    "C015,2022-10-03,570.00\n",
    "C010,2022-11-01,390.00\n",
    "C011,2022-11-02,520.00\n",
    "C012,2022-11-03,710.00\n",
    "C013,2022-12-01,400.00\n",
    "C014,2022-12-02,530.00\n",
    "C015,2022-12-03,770.00\n",
    "C010,2023-01-01,410.00\n",
    "C011,2023-01-02,540.00\n",
    "C012,2023-01-03,810.00\n",
    "C013,2023-02-01,430.00\n",
    "C014,2023-02-02,570.00\n",
    "C015,2023-02-03,870.00\n",
    "C010,2023-03-01,460.00\n",
    "C011,2023-03-02,610.00\n",
    "C012,2023-03-03,910.00\n",
    "C013,2023-04-01,490.00\n",
    "C014,2023-04-02,650.00\n",
    "C015,2023-04-03,970.00\n",
    "C010,2023-05-01,510.00\n",
    "C011,2023-05-02,690.00\n",
    "C012,2023-05-03,1010.00\n",
    "C013,2023-06-01,540.00\n",
    "C014,2023-06-02,720.00\n",
    "C015,2023-06-03,1050.00\n",
    "C010,2023-07-01,570.00\n",
    "C011,2023-07-02,750.00\n",
    "C012,2023-07-03,1090.00\n",
    "C013,2023-08-01,600.00\n",
    "C014,2023-08-02,790.00\n",
    "C015,2023-08-03,1130.00\n",
    "C010,2023-09-01,630.00\n",
    "C011,2023-09-02,830.00\n",
    "C012,2023-09-03,1170.00\n",
    "C013,2023-10-01,660.00\n",
    "C014,2023-10-02,870.00\n",
    "C015,2023-10-03,1210.00\n",
    "C010,2023-11-01,690.00\n",
    "C011,2023-11-02,910.00\n",
    "C012,2023-11-03,1250.00\n",
    "C013,2023-12-01,720.00\n",
    "C014,2023-12-02,950.00\n",
    "C015,2023-12-03,1290.00\n",
    "\"\"\"\n",
    "\n",
    "# Combine the original and additional data\n",
    "data += additional_data\n",
    "\n",
    "# Read the data using pandas\n",
    "cust = pd.read_csv(StringIO(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust.groupby('Customer_ID')['Transaction_Amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = cust.groupby('Customer_ID', as_index=False)[['Transaction_Amount']].sum()\n",
    "totals.columns = ['Customer_ID', 'Total_Transaction_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = cust.groupby('Customer_ID', as_index=False)[['Transaction_Amount']].mean()\n",
    "averages.columns = ['Customer_ID', 'Average_Transaction_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = cust.groupby('Customer_ID', as_index=False)[['Transaction_Amount']].count()\n",
    "counts.columns = ['Customer_ID', 'Count_Transaction_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_days = cust.groupby('Customer_ID', as_index=False)[['Transaction_Date']].nunique()   \n",
    "unique_days.columns = ['Customer_ID', 'Count_Unique_Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a df using merge on totals, averages, counts, and unique_days\n",
    "aggs = totals.merge(averages, on='Customer_ID')\n",
    "aggs = aggs.merge(counts, on='Customer_ID')\n",
    "aggs = aggs.merge(unique_days, on='Customer_ID')\n",
    "aggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs['Purchase_Frequency'] = aggs['Count_Transaction_Amount'] / aggs['Count_Unique_Days']\n",
    "aggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Means on the customers\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Make three clusters from the aggs dataframe. We want to batch customers, or \"Customer_IDs\" into three groups\n",
    "kmeans = KMeans(n_clusters=3).fit(aggs.drop('Customer_ID', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "\n",
    "You work as a data scientist at a healthcare company. Your current task is to analyze the date and time of patient appointments. You are given a CSV string of patient appointment data, with each row containing a patient ID and the date and time of their appointment in 'YYYY-MM-DD HH:MM:SS' format.\n",
    "\n",
    "Your task is to write a Python snippet that:\n",
    "- Reads this CSV data into a pandas DataFrame.\n",
    "- Transforms the date and time into a datetime object.\n",
    "- Extracts the day of the week from the datetime object (0 is Monday and 6 is Sunday).\n",
    "- Counts the number of appointments each patient had on each day of the week.\n",
    "- Adds up all the Monday appointments and computes the average number of Monday appointments per patient.\n",
    "\n",
    "The dataset is provided as follows:\n",
    "\n",
    "```csv\n",
    "\"Patient_ID,Appointment_Date\n",
    "P001,2023-01-01 10:30:00\n",
    "P002,2023-01-01 11:00:00\n",
    "P001,2023-01-02 09:00:00\n",
    "P002,2023-01-03 15:30:00\n",
    "P001,2023-01-04 10:00:00\n",
    "P002,2023-01-05 14:00:00\n",
    "P001,2023-01-06 10:30:00\n",
    "P002,2023-01-07 09:30:00\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Appointment_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>2023-01-01 10:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>2023-01-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P001</td>\n",
       "      <td>2023-01-02 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P002</td>\n",
       "      <td>2023-01-03 15:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P001</td>\n",
       "      <td>2023-01-04 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P002</td>\n",
       "      <td>2023-01-05 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P001</td>\n",
       "      <td>2023-01-06 10:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P002</td>\n",
       "      <td>2023-01-07 09:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient_ID     Appointment_Date\n",
       "0       P001  2023-01-01 10:30:00\n",
       "1       P002  2023-01-01 11:00:00\n",
       "2       P001  2023-01-02 09:00:00\n",
       "3       P002  2023-01-03 15:30:00\n",
       "4       P001  2023-01-04 10:00:00\n",
       "5       P002  2023-01-05 14:00:00\n",
       "6       P001  2023-01-06 10:30:00\n",
       "7       P002  2023-01-07 09:30:00"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "data_string = '''Patient_ID,Appointment_Date\n",
    "P001,2023-01-01 10:30:00\n",
    "P002,2023-01-01 11:00:00\n",
    "P001,2023-01-02 09:00:00\n",
    "P002,2023-01-03 15:30:00\n",
    "P001,2023-01-04 10:00:00\n",
    "P002,2023-01-05 14:00:00\n",
    "P001,2023-01-06 10:30:00\n",
    "P002,2023-01-07 09:30:00'''\n",
    "\n",
    "patients = pd.read_csv(StringIO(data_string), sep=\",\")\n",
    "patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['Appointment_Date'] = patients['Appointment_Date'].astype('datetime64[ns]')\n",
    "# patients['Appointment_Weekday'] is weekday as a number where monday is 0 and sunday is 6\n",
    "patients['Appointment_Weekday'] = patients['Appointment_Date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Appointment_Date</th>\n",
       "      <th>Appointment_Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>2023-01-01 10:30:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>2023-01-01 11:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P001</td>\n",
       "      <td>2023-01-02 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P002</td>\n",
       "      <td>2023-01-03 15:30:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P001</td>\n",
       "      <td>2023-01-04 10:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P002</td>\n",
       "      <td>2023-01-05 14:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P001</td>\n",
       "      <td>2023-01-06 10:30:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P002</td>\n",
       "      <td>2023-01-07 09:30:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient_ID    Appointment_Date  Appointment_Weekday\n",
       "0       P001 2023-01-01 10:30:00                    6\n",
       "1       P002 2023-01-01 11:00:00                    6\n",
       "2       P001 2023-01-02 09:00:00                    0\n",
       "3       P002 2023-01-03 15:30:00                    1\n",
       "4       P001 2023-01-04 10:00:00                    2\n",
       "5       P002 2023-01-05 14:00:00                    3\n",
       "6       P001 2023-01-06 10:30:00                    4\n",
       "7       P002 2023-01-07 09:30:00                    5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Appointment_Weekday</th>\n",
       "      <th>Appointment_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P001</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P002</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P002</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P002</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient_ID  Appointment_Weekday  Appointment_Date\n",
       "0       P001                    0                 1\n",
       "1       P001                    2                 1\n",
       "2       P001                    4                 1\n",
       "3       P001                    6                 1\n",
       "4       P002                    1                 1\n",
       "5       P002                    3                 1\n",
       "6       P002                    5                 1\n",
       "7       P002                    6                 1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients.groupby(['Patient_ID', 'Appointment_Weekday'],as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Appointment_Date</th>\n",
       "      <th>Appointment_Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient_ID  Appointment_Date  Appointment_Weekday\n",
       "0       P001                 1                    1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mondays = patients.loc[patients['Appointment_Weekday'] == 0]\n",
    "mondays.groupby('Patient_ID', as_index=False).count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "You have a CSV dataset containing information about 100 articles. Each article has an ID, a title, a category (e.g., 'technology', 'sports', 'culture', etc.), and the number of views it has received.\n",
    "\n",
    "You're tasked to perform the following operations using list comprehensions:\n",
    "\n",
    "1. Extract all article titles that belong to the 'technology' category.\n",
    "2. From the list of technology articles, extract the ones that have received more than 5000 views.\n",
    "3. Create a new list of all articles (from the entire dataset) with their titles capitalized.\n",
    "\n",
    "Here's the format of the data:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Libraries Needed: pandas, io\n",
    "\n",
    "#### Inputs:\n",
    "\n",
    "A string representing a CSV file that includes the following columns:\n",
    "Article_ID: an integer that uniquely identifies each article\n",
    "Title: a string representing the title of the article\n",
    "Category: a string representing the category of the article\n",
    "Views: an integer representing the number of views the article has received\n",
    "#### Expected Outputs:\n",
    "\n",
    "A list of strings representing the titles of articles in the 'technology' category.\n",
    "A list of strings representing the titles of technology articles that have received more than 5000 views.\n",
    "A list of strings representing the titles of all articles, with each title capitalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the CSV data\n",
    "data_string = '''Article_ID,Title,Category,Views\\n''' + '\\n'.join([f'{i+1},Article {i+1},{[\"Technology\",\"Sports\",\"Culture\"][i%3]},{(i+1)*50}' for i in range(100)])\n",
    "\n",
    "# Your code goes here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Article 1</td>\n",
       "      <td>Technology</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Article 2</td>\n",
       "      <td>Sports</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Article 3</td>\n",
       "      <td>Culture</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Article 4</td>\n",
       "      <td>Technology</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Article 5</td>\n",
       "      <td>Sports</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Article 96</td>\n",
       "      <td>Culture</td>\n",
       "      <td>4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Article 97</td>\n",
       "      <td>Technology</td>\n",
       "      <td>4850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Article 98</td>\n",
       "      <td>Sports</td>\n",
       "      <td>4900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Article 99</td>\n",
       "      <td>Culture</td>\n",
       "      <td>4950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Article 100</td>\n",
       "      <td>Technology</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Article_ID        Title    Category  Views\n",
       "0            1    Article 1  Technology     50\n",
       "1            2    Article 2      Sports    100\n",
       "2            3    Article 3     Culture    150\n",
       "3            4    Article 4  Technology    200\n",
       "4            5    Article 5      Sports    250\n",
       "..         ...          ...         ...    ...\n",
       "95          96   Article 96     Culture   4800\n",
       "96          97   Article 97  Technology   4850\n",
       "97          98   Article 98      Sports   4900\n",
       "98          99   Article 99     Culture   4950\n",
       "99         100  Article 100  Technology   5000\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "# Load the data into a pandas DataFrame\n",
    "articles = pd.read_csv(StringIO(data_string), sep=\",\")\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Article 1',\n",
       " 'Article 4',\n",
       " 'Article 7',\n",
       " 'Article 10',\n",
       " 'Article 13',\n",
       " 'Article 16',\n",
       " 'Article 19',\n",
       " 'Article 22',\n",
       " 'Article 25',\n",
       " 'Article 28',\n",
       " 'Article 31',\n",
       " 'Article 34',\n",
       " 'Article 37',\n",
       " 'Article 40',\n",
       " 'Article 43',\n",
       " 'Article 46',\n",
       " 'Article 49',\n",
       " 'Article 52',\n",
       " 'Article 55',\n",
       " 'Article 58',\n",
       " 'Article 61',\n",
       " 'Article 64',\n",
       " 'Article 67',\n",
       " 'Article 70',\n",
       " 'Article 73',\n",
       " 'Article 76',\n",
       " 'Article 79',\n",
       " 'Article 82',\n",
       " 'Article 85',\n",
       " 'Article 88',\n",
       " 'Article 91',\n",
       " 'Article 94',\n",
       " 'Article 97',\n",
       " 'Article 100']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List of strings for article titles in the Technology category\n",
    "articles.loc[articles['Category'] == 'Technology']['Title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Article 13',\n",
       " 'Article 16',\n",
       " 'Article 19',\n",
       " 'Article 22',\n",
       " 'Article 25',\n",
       " 'Article 28',\n",
       " 'Article 31',\n",
       " 'Article 34',\n",
       " 'Article 37',\n",
       " 'Article 40',\n",
       " 'Article 43',\n",
       " 'Article 46',\n",
       " 'Article 49',\n",
       " 'Article 52',\n",
       " 'Article 55',\n",
       " 'Article 58',\n",
       " 'Article 61',\n",
       " 'Article 64',\n",
       " 'Article 67',\n",
       " 'Article 70',\n",
       " 'Article 73',\n",
       " 'Article 76',\n",
       " 'Article 79',\n",
       " 'Article 82',\n",
       " 'Article 85',\n",
       " 'Article 88',\n",
       " 'Article 91',\n",
       " 'Article 94',\n",
       " 'Article 97',\n",
       " 'Article 100']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.loc[(articles['Category'] == 'Technology') & (articles['Views'] > 500)]['Title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARTICLE 1',\n",
       " 'ARTICLE 2',\n",
       " 'ARTICLE 3',\n",
       " 'ARTICLE 4',\n",
       " 'ARTICLE 5',\n",
       " 'ARTICLE 6',\n",
       " 'ARTICLE 7',\n",
       " 'ARTICLE 8',\n",
       " 'ARTICLE 9',\n",
       " 'ARTICLE 10',\n",
       " 'ARTICLE 11',\n",
       " 'ARTICLE 12',\n",
       " 'ARTICLE 13',\n",
       " 'ARTICLE 14',\n",
       " 'ARTICLE 15',\n",
       " 'ARTICLE 16',\n",
       " 'ARTICLE 17',\n",
       " 'ARTICLE 18',\n",
       " 'ARTICLE 19',\n",
       " 'ARTICLE 20',\n",
       " 'ARTICLE 21',\n",
       " 'ARTICLE 22',\n",
       " 'ARTICLE 23',\n",
       " 'ARTICLE 24',\n",
       " 'ARTICLE 25',\n",
       " 'ARTICLE 26',\n",
       " 'ARTICLE 27',\n",
       " 'ARTICLE 28',\n",
       " 'ARTICLE 29',\n",
       " 'ARTICLE 30',\n",
       " 'ARTICLE 31',\n",
       " 'ARTICLE 32',\n",
       " 'ARTICLE 33',\n",
       " 'ARTICLE 34',\n",
       " 'ARTICLE 35',\n",
       " 'ARTICLE 36',\n",
       " 'ARTICLE 37',\n",
       " 'ARTICLE 38',\n",
       " 'ARTICLE 39',\n",
       " 'ARTICLE 40',\n",
       " 'ARTICLE 41',\n",
       " 'ARTICLE 42',\n",
       " 'ARTICLE 43',\n",
       " 'ARTICLE 44',\n",
       " 'ARTICLE 45',\n",
       " 'ARTICLE 46',\n",
       " 'ARTICLE 47',\n",
       " 'ARTICLE 48',\n",
       " 'ARTICLE 49',\n",
       " 'ARTICLE 50',\n",
       " 'ARTICLE 51',\n",
       " 'ARTICLE 52',\n",
       " 'ARTICLE 53',\n",
       " 'ARTICLE 54',\n",
       " 'ARTICLE 55',\n",
       " 'ARTICLE 56',\n",
       " 'ARTICLE 57',\n",
       " 'ARTICLE 58',\n",
       " 'ARTICLE 59',\n",
       " 'ARTICLE 60',\n",
       " 'ARTICLE 61',\n",
       " 'ARTICLE 62',\n",
       " 'ARTICLE 63',\n",
       " 'ARTICLE 64',\n",
       " 'ARTICLE 65',\n",
       " 'ARTICLE 66',\n",
       " 'ARTICLE 67',\n",
       " 'ARTICLE 68',\n",
       " 'ARTICLE 69',\n",
       " 'ARTICLE 70',\n",
       " 'ARTICLE 71',\n",
       " 'ARTICLE 72',\n",
       " 'ARTICLE 73',\n",
       " 'ARTICLE 74',\n",
       " 'ARTICLE 75',\n",
       " 'ARTICLE 76',\n",
       " 'ARTICLE 77',\n",
       " 'ARTICLE 78',\n",
       " 'ARTICLE 79',\n",
       " 'ARTICLE 80',\n",
       " 'ARTICLE 81',\n",
       " 'ARTICLE 82',\n",
       " 'ARTICLE 83',\n",
       " 'ARTICLE 84',\n",
       " 'ARTICLE 85',\n",
       " 'ARTICLE 86',\n",
       " 'ARTICLE 87',\n",
       " 'ARTICLE 88',\n",
       " 'ARTICLE 89',\n",
       " 'ARTICLE 90',\n",
       " 'ARTICLE 91',\n",
       " 'ARTICLE 92',\n",
       " 'ARTICLE 93',\n",
       " 'ARTICLE 94',\n",
       " 'ARTICLE 95',\n",
       " 'ARTICLE 96',\n",
       " 'ARTICLE 97',\n",
       " 'ARTICLE 98',\n",
       " 'ARTICLE 99',\n",
       " 'ARTICLE 100']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A list of strings representing the titles of all articles, with each title capitalized.\n",
    "articles['Title'].str.upper().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Date,Sales\n",
    "2023-01-01, 1000\n",
    "2023-01-02, 1200\n",
    "2023-01-03, 1100\n",
    "...\n",
    "2023-04-10, 1500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_string = '''Date,Sales\\n''' + '\\n'.join([f'2023-01-{str(i+1).zfill(2)},{(i+1)*100}' for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Overview:\n",
    "\n",
    "You are given a DataFrame that contains information about a company's sales data. The DataFrame has the following columns: 'Product', 'Quantity Sold', 'Sales', and 'Date'. 'Product' is the name of the product sold, 'Quantity Sold' is the number of units sold, 'Sales' is the total sales in dollars, and 'Date' is the date of the sale.\n",
    "\n",
    "Your task is to write a function that calculates the top 3 products with the highest total sales in a given month and year.\n",
    "\n",
    "The function should return a new DataFrame with the product names and their total sales, sorted in descending order of sales.\n",
    "\n",
    "Libraries Needed:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "from pandas import Timestamp\n",
    "Inputs:\n",
    "\n",
    "The function will take the following inputs:\n",
    "\n",
    "A DataFrame 'df' with the sales data. The DataFrame will have the following columns:\n",
    "'Product': string, the name of the product sold.\n",
    "'Quantity Sold': integer, the number of units of the product sold.\n",
    "'Sales': float, the total sales of the product in dollars.\n",
    "'Date': Timestamp, the date of the sale.\n",
    "'month': integer, the month for which to calculate the top products.\n",
    "'year': integer, the year for which to calculate the top products.\n",
    "Expected Outputs:\n",
    "\n",
    "The function should return a new DataFrame with two columns: 'Product' and 'Total Sales'. The DataFrame should contain the top 3 products with the highest total sales in the given month and year, sorted in descending order of total sales. If there are fewer than 3 products sold in the given month and year, the DataFrame should contain all the products sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"Product\": \"A\", \"Quantity Sold\": 10, \"Sales\": 100.0, \"Date\": \"2023-01-01\"},\n",
    "    {\"Product\": \"B\", \"Quantity Sold\": 5, \"Sales\": 50.0, \"Date\": \"2023-01-01\"},\n",
    "    {\"Product\": \"C\", \"Quantity Sold\": 8, \"Sales\": 80.0, \"Date\": \"2023-01-01\"},\n",
    "    {\"Product\": \"A\", \"Quantity Sold\": 7, \"Sales\": 70.0, \"Date\": \"2023-01-02\"},\n",
    "    {\"Product\": \"B\", \"Quantity Sold\": 2, \"Sales\": 20.0, \"Date\": \"2023-01-02\"},\n",
    "    {\"Product\": \"A\", \"Quantity Sold\": 5, \"Sales\": 50.0, \"Date\": \"2023-02-01\"},\n",
    "    {\"Product\": \"B\", \"Quantity Sold\": 10, \"Sales\": 100.0, \"Date\": \"2023-02-01\"},\n",
    "    {\"Product\": \"C\", \"Quantity Sold\": 6, \"Sales\": 60.0, \"Date\": \"2023-02-01\"},\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_products(df, month, year):\n",
    "    # Filter the sales by given month and year\n",
    "    filtered_df = df[(df['Date'].dt.month == month) & (df['Date'].dt.year == year)]\n",
    "    \n",
    "    # Create a grouped DataFrame by summing the sales for each product\n",
    "    group_df = filtered_df.groupby('Product')['Sales'].sum()\n",
    "    \n",
    "    # Sort the products by their total sales and select the top 3\n",
    "    top_products = group_df.sort_values(ascending=False).head(3)\n",
    "    \n",
    "    # Results in a DataFrame format\n",
    "    result = pd.DataFrame(top_products).reset_index().rename(columns={'Product': 'Product', 'Sales': 'Total Sales'})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Total Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product  Total Sales\n",
       "0       B        100.0\n",
       "1       C         60.0\n",
       "2       A         50.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_products(df, 2, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Total Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product  Total Sales\n",
       "0       A        170.0\n",
       "1       C         80.0\n",
       "2       B         70.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_products(df, 1, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Overview:\n",
    "\n",
    "You are given a NumPy array that contains the heights (in cm) of a group of people. Write a function that calculates and returns the mean, median, and standard deviation of the heights.\n",
    "\n",
    "The function should return a dictionary where the keys are the names of the measures ('mean', 'median', 'std') and the values are the calculated measures.\n",
    "\n",
    "#### Libraries Needed:\n",
    "\n",
    "```python\n",
    "\n",
    "import numpy as \n",
    "```\n",
    "#### Inputs:\n",
    "\n",
    "The function will take the following input:\n",
    "\n",
    "A NumPy array 'heights' with the heights of the group of people. The array contains positive floats.\n",
    "Expected Outputs:\n",
    "\n",
    "The function should return a dictionary. The dictionary should have three keys: 'mean', 'median', and 'std'. The values should be the mean, median, and standard deviation of the heights, respectively. All values should be rounded to 2 decimal places.\n",
    "\n",
    "Data:\n",
    "```python\n",
    "heights = np.array([170.1, 165.8, 172.8, 180.5, 168.4, 174.2, 169.5, 175.6])\n",
    "```\n",
    "##### Encrypted Solution:\n",
    "\n",
    "Here's the solution, encrypted with a Caesar cipher with a shift of 3 to the right:\n",
    "\n",
    "python\n",
    "```\n",
    "ghilqk_swdwvwlfdovk(dohlkwv):\n",
    "    phdq = qsb.uroxqg(qsb.phdq(dohlkwv), 2)\n",
    "    phgldq = qsb.uroxqg(qsb.phgldq(dohlkwv), 2)\n",
    "    vwg = qsb.uroxqg(qsb.vwg(dohlkwv), 2)\n",
    "    \n",
    "    uhvxow = {'phdq': phdq, 'phgldq': phgldq, 'vwg': vwg}\n",
    "    \n",
    "    uhwxuq uhvxow\n",
    "```\n",
    "The shift of 3 letters to the right was applied to every letter of the solution, but not to special characters, digits or whitespaces.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "heights = np.array([170.1, 165.8, 172.8, 180.5, 168.4, 174.2, 169.5, 175.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean': 172.11, 'Median': 171.45, 'Standard Deviation': 4.36}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_descriptive_stats(array):\n",
    "    mean = round(np.mean(array),2)\n",
    "    median = round(np.median(array),2)\n",
    "    std_dev = round(np.std(array),2)\n",
    "    descriptive_stats = {\"Mean\": mean,\n",
    "                         \"Median\": median,\n",
    "                         \"Standard Deviation\": std_dev}\n",
    "    return descriptive_stats\n",
    "\n",
    "get_descriptive_stats(heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171.45"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(heights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making this more challenging with the following:\n",
    "- '25th percentile': the 25th percentile of the heights, rounded to 2 decimal places.\n",
    "- '75th percentile': the 75th percentile of the heights, rounded to 2 decimal places.\n",
    "- 'normality test': a string that states either 'The distribution is normal' or 'The distribution is not normal'. The normality of the distribution is tested using the Shapiro-Wilk test. If the p-value is greater than 0.05, the function should return 'The distribution is normal'. Otherwise, it should return 'The distribution is not normal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean': 172.11,\n",
       " '25th percentile': 174.5,\n",
       " 'Median': 171.45,\n",
       " 'Standard Deviation': 4.36,\n",
       " '75th percentile': 174.5,\n",
       " 'Normality': 'The distribution is normal'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_descriptive_stats(array):\n",
    "    mean = round(np.mean(array),2)\n",
    "    median = round(np.median(array),2)\n",
    "    std_dev = round(np.std(array),2)\n",
    "    pct_25 = round(np.percentile(heights, 75),1)\n",
    "    pct_75 = round(np.percentile(heights, 75),1)\n",
    "    w, pvalue = stats.shapiro(heights)\n",
    "    if pvalue > 0.05:\n",
    "        normality_test = 'The distribution is normal'\n",
    "    else:\n",
    "        normality_test = 'The distribution is not normal'\n",
    "    descriptive_stats = {\"Mean\": mean,\n",
    "                         \"25th percentile\": pct_25,\n",
    "                         \"Median\": median,\n",
    "                         \"Standard Deviation\": std_dev,\n",
    "                         \"75th percentile\": pct_75,\n",
    "                         \"Normality\": normality_test}\n",
    "    \n",
    "    return descriptive_stats\n",
    "get_descriptive_stats(heights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>Shapiro-Wilk test</b> is a statistical test that checks whether a given sample of data follows a normal distribution. It is named after Samuel Sanford Shapiro and Martin Wilk, who developed the test.\n",
    "\n",
    "<b>The null hypothesis for the Shapiro-Wilk test is that the data are normally distributed.</b> Therefore, if the p-value returned from the test is less than the chosen significance level (commonly set at 0.05), then the null hypothesis is rejected and there is evidence to suggest that the data are not normally distributed.\n",
    "\n",
    "In the context of the function calculate_statistics_extended, the Shapiro-Wilk test is used to check if the heights follow a normal distribution.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "- The <i>stats.shapiro</i> function from the scipy library is used to perform the Shapiro-Wilk test on the heights data. The function returns two values: w and pvalue. w is the test statistic, and pvalue is the p-value of the test.\n",
    "- If pvalue is greater than 0.05, the function concludes that the heights follow a normal distribution ('The distribution is normal'). This is because a p-value greater than 0.05 means that we fail to reject the null hypothesis that the data are normally distributed.\n",
    "- If pvalue is less than or equal to 0.05, the function concludes that the heights do not follow a normal distribution ('The distribution is not normal'). This is because a p-value less than or equal to 0.05 means that we reject the null hypothesis that the data are normally distributed.\n",
    "\n",
    "\n",
    "<b>Remember that failing to reject the null hypothesis does not prove the null hypothesis to be true.</b> It just means that there is not enough evidence to conclude that the data are not normally distributed. Similarly, rejecting the null hypothesis does not prove the alternative hypothesis to be true. It just means that there is enough evidence to conclude that the data are not normally distributed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "You work as a data scientist for a company. They have provided you with sales data for various products across different regions. Each row in the dataset corresponds to a sale. Your task is to write a function that calculates the average sales per product per region.\n",
    "\n",
    "The function should also calculate a new feature: the percentage of total sales that each product accounts for within each region. For example, if product A sold 50 units in region 1, and the total sales in region 1 were 200 units, then the percentage of total sales for product A in region 1 would be 25%.\n",
    "\n",
    "The results should be sorted in descending order by the average sales, and then by the percentage of total sales.\n",
    "\n",
    "## Inputs:\n",
    "The function, `calculate_average_sales(df: pd.DataFrame) -> pd.DataFrame`, takes in a pandas DataFrame `df` with the following columns:\n",
    "- 'product' (str): The name of the product.\n",
    "- 'region' (str): The region where the product was sold.\n",
    "- 'sales' (int): The number of units sold.\n",
    "\n",
    "## Outputs:\n",
    "The function should return a DataFrame with the following columns:\n",
    "- 'product' (str): The name of the product.\n",
    "- 'region' (str): The region.\n",
    "- 'average_sales' (float): The average number of units sold per product per region.\n",
    "- 'percentage_of_total_sales' (float): The percentage of total sales that each product accounts for within each region.\n",
    "\n",
    "The DataFrame should be sorted in descending order first by 'average_sales', and then by 'percentage_of_total_sales'.\n",
    "\n",
    "## Libraries Needed:\n",
    "- pandas\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data:\n",
    "Here is the sales data in JSON format:\n",
    "\n",
    "```python\n",
    "data = \"\"\"\n",
    "[\n",
    "    {\"product\": \"Apple\", \"region\": \"North\", \"sales\": 100},\n",
    "    {\"product\": \"Banana\", \"region\": \"North\", \"sales\": 150},\n",
    "    {\"product\": \"Cherry\", \"region\": \"North\", \"sales\": 200},\n",
    "    {\"product\": \"Apple\", \"region\": \"North\", \"sales\": 150},\n",
    "    {\"product\": \"Banana\", \"region\": \"North\", \"sales\": 200},\n",
    "    {\"product\": \"Cherry\", \"region\": \"North\", \"sales\": 250},\n",
    "    {\"product\": \"Apple\", \"region\": \"South\", \"sales\": 200},\n",
    "    {\"product\": \"Banana\", \"region\": \"South\", \"sales\": 250},\n",
    "    {\"product\": \"Cherry\", \"region\": \"South\", \"sales\": 300},\n",
    "    {\"product\": \"Apple\", \"region\": \"South\", \"sales\": 250},\n",
    "    {\"product\": \"Banana\", \"region\": \"South\", \"sales\": 300},\n",
    "    {\"product\": \"Cherry\", \"region\": \"South\", \"sales\": 350}\n",
    "]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"product\": \"Apple\", \"region\": \"North\", \"sales\": 100},\n",
    "    {\"product\": \"Banana\", \"region\": \"North\", \"sales\": 150},\n",
    "    {\"product\": \"Cherry\", \"region\": \"North\", \"sales\": 200},\n",
    "    {\"product\": \"Apple\", \"region\": \"North\", \"sales\": 150},\n",
    "    {\"product\": \"Banana\", \"region\": \"North\", \"sales\": 200},\n",
    "    {\"product\": \"Cherry\", \"region\": \"North\", \"sales\": 250},\n",
    "    {\"product\": \"Apple\", \"region\": \"South\", \"sales\": 200},\n",
    "    {\"product\": \"Banana\", \"region\": \"South\", \"sales\": 250},\n",
    "    {\"product\": \"Cherry\", \"region\": \"South\", \"sales\": 300},\n",
    "    {\"product\": \"Apple\", \"region\": \"South\", \"sales\": 250},\n",
    "    {\"product\": \"Banana\", \"region\": \"South\", \"sales\": 300},\n",
    "    {\"product\": \"Cherry\", \"region\": \"South\", \"sales\": 350}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>region</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>North</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banana</td>\n",
       "      <td>North</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cherry</td>\n",
       "      <td>North</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>North</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Banana</td>\n",
       "      <td>North</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cherry</td>\n",
       "      <td>North</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apple</td>\n",
       "      <td>South</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Banana</td>\n",
       "      <td>South</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cherry</td>\n",
       "      <td>South</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apple</td>\n",
       "      <td>South</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Banana</td>\n",
       "      <td>South</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cherry</td>\n",
       "      <td>South</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product region  sales\n",
       "0    Apple  North    100\n",
       "1   Banana  North    150\n",
       "2   Cherry  North    200\n",
       "3    Apple  North    150\n",
       "4   Banana  North    200\n",
       "5   Cherry  North    250\n",
       "6    Apple  South    200\n",
       "7   Banana  South    250\n",
       "8   Cherry  South    300\n",
       "9    Apple  South    250\n",
       "10  Banana  South    300\n",
       "11  Cherry  South    350"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.DataFrame(data)\n",
    "sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>region</th>\n",
       "      <th>sales</th>\n",
       "      <th>percentage_of_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>North</td>\n",
       "      <td>250</td>\n",
       "      <td>9.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>South</td>\n",
       "      <td>450</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banana</td>\n",
       "      <td>North</td>\n",
       "      <td>350</td>\n",
       "      <td>12.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Banana</td>\n",
       "      <td>South</td>\n",
       "      <td>550</td>\n",
       "      <td>20.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cherry</td>\n",
       "      <td>North</td>\n",
       "      <td>450</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cherry</td>\n",
       "      <td>South</td>\n",
       "      <td>650</td>\n",
       "      <td>24.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product region  sales  percentage_of_total\n",
       "0   Apple  North    250                 9.26\n",
       "1   Apple  South    450                16.67\n",
       "2  Banana  North    350                12.96\n",
       "3  Banana  South    550                20.37\n",
       "4  Cherry  North    450                16.67\n",
       "5  Cherry  South    650                24.07"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_sales = sales.groupby(['product', 'region'], as_index=False)['sales'].sum()\n",
    "total_sales = grouped_sales['sales'].sum()\n",
    "grouped_sales['percentage_of_total'] = round(grouped_sales['sales'] / total_sales,4) * 100\n",
    "grouped_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_sales(df):\n",
    "    average_sales = df.groupby(['product', 'region'])['sales'].mean().reset_index().rename(columns={'sales': 'average_sales'})\n",
    "    total_sales = df.groupby('region')['sales'].sum().reset_index().rename(columns={'sales': 'total_sales'})\n",
    "    result = pd.merge(average_sales, total_sales, on='region')\n",
    "    result['sales_percentage'] = round(result['average_sales'] / result['total_sales'], 4) * 100\n",
    "    result = result.sort_values(by=['average_sales', 'sales_percentage'], ascending=False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>region</th>\n",
       "      <th>average_sales</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>sales_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cherry</td>\n",
       "      <td>South</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1650</td>\n",
       "      <td>19.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Banana</td>\n",
       "      <td>South</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1650</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cherry</td>\n",
       "      <td>North</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1050</td>\n",
       "      <td>21.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>South</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1650</td>\n",
       "      <td>13.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banana</td>\n",
       "      <td>North</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1050</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>North</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1050</td>\n",
       "      <td>11.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product region  average_sales  total_sales  sales_percentage\n",
       "5  Cherry  South          325.0         1650             19.70\n",
       "4  Banana  South          275.0         1650             16.67\n",
       "2  Cherry  North          225.0         1050             21.43\n",
       "3   Apple  South          225.0         1650             13.64\n",
       "1  Banana  North          175.0         1050             16.67\n",
       "0   Apple  North          125.0         1050             11.90"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_average_sales(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
