{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of your code should be the original DataFrame, but with missing values in the 'Revenue' column filled in as described, a new 'Rating Category' column, and the mean revenue for each 'Rating Category'. The mean revenue should be output as a pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies_df = pd.read_clipboard(sep=',')\n",
    "#movies_df.to_csv(\"movies_sample.csv\", index=False)\n",
    "movies_df = pd.read_csv(\"movies_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_revenue = movies_df['Revenue'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.Revenue.fillna(median_revenue, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_films(x):\n",
    "    if x >= 8.5:\n",
    "        return \"Excellent\"\n",
    "    elif x >= 7:\n",
    "        return \"Very Good\"\n",
    "    elif x >= 5.5:\n",
    "        return \"Good\"\n",
    "    else:\n",
    "        return \"Average\"\n",
    "\n",
    "\n",
    "movies_df[\"Rating Category\"] = movies_df[\"Rating\"].apply(rate_films)\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.groupby(\"Rating Category\")[['Revenue']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generated solution\n",
    "import pandas as pd\n",
    "movies_df['Decade'] = movies_df['Year'].apply(lambda x: f\"{x//10*10}_{x//10*10+9}\")\n",
    "movies_df['Revenue'] = movies_df.groupby(['Decade', 'Genre'])['Revenue'].transform(lambda x: x.fillna(x.median()))\n",
    "movies_df['Rating Category'] = pd.cut(movies_df['Rating'], bins=[0,5.5,7,8.5,10], labels=['Average','Good','Very Good','Excellent'])\n",
    "mean_revenue = movies_df.groupby('Rating Category').mean()['Revenue']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the revenue null value fills, the generated answer makes a great point:\n",
    " - The expression {movies_df.groupby(['Decade', 'Genre'])['Revenue'].transform(lambda x: x.fillna(x.median()))} is an example of a more sophisticated method of data imputation, which takes into account the context of the missing data.\n",
    "\n",
    "- In this case, you're filling in missing 'Revenue' values with the median revenue of movies that are in the same genre and were released in the same decade. This makes sense because movies from the same genre and decade are more likely to have similar revenues compared to movies from a different genre or time period. This method provides a more accurate estimate of the missing values.\n",
    "\n",
    "- On the other hand, median_revenue = movies['Revenue'].median() calculates the median revenue across all movies, regardless of their genre or release date. If you were to fill in missing values with this median, you'd be ignoring the context in which the data is missing. For example, you'd be treating a drama movie from the 1980s the same as an action movie from the 2020s, even though these types of movies might have very different revenues.\n",
    "\n",
    "- Therefore, the first method is generally better because it's more likely to provide an accurate estimate of the missing data. However, the best method to use always depends on the specific dataset and problem at hand.\n",
    "\n",
    "for the rating category, I also learned a bunch.\n",
    "- movies_df['Rating Category'] = pd.cut(movies_df['Rating'], bins=[0,5.5,7,8.5,10], labels=['Average','Good','Very Good','Excellent'])\n",
    "- This line of code is using the pd.cut() function to create a new column in the DataFrame called 'Rating Category'. The pd.cut() function is a way to create categories (or \"bins\") based on numeric values. In this case, it's being used to categorize the 'Rating' column into different groups based on the rating score.\n",
    "\n",
    "- The bins argument is specifying the boundaries for each category. The list [0,5.5,7,8.5,10] means that the categories are:\n",
    "\n",
    "- This line of code is essentially mapping each movie's rating to a category. It's an example of \"binning\" or \"bucketing\", which are common techniques used in data analysis and machine learning to deal with continuous variables. In this case, it's being used to simplify the 'Rating' column and make it easier to analyze."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are given a list of dictionaries where each dictionary represents a movie. Each dictionary has the following key-value pairs:\n",
    "\n",
    "- 'Title': The title of the movie (string).\n",
    "- 'Genre': The genre of the movie (string).\n",
    "- 'Year': The year the movie was released (integer).\n",
    "- 'Runtime': The length of the movie in minutes (integer).\n",
    "- 'Rating': The average user rating out of 10 (float).\n",
    "Your task is to write a Python function that takes in this list and a genre, and returns the average rating of movies in that genre.\n",
    "\n",
    "In addition, write an SQL query that would perform the same operation on a table with the same columns.\n",
    "\n",
    "### Libraries Needed\n",
    "\n",
    "- Python: None\n",
    "- SQL: None (but you need to know SQL syntax)\n",
    "Inputs\n",
    "\n",
    "### The Python function average_rating_by_genre(movies: List[dict], genre: str) -> float: takes in two arguments:\n",
    "\n",
    "- movies: a list of dictionaries where each dictionary represents a movie with the key-value pairs described above.\n",
    "- genre: a string representing the genre of the movies for which you want to calculate the average rating.\n",
    "The SQL query should be written assuming you have a table named movies with the same columns as the dictionaries in the Python function.\n",
    "\n",
    "## Expected Outputs\n",
    "\n",
    "The Python function should return a float representing the average rating of movies in the input genre.\n",
    "\n",
    "The SQL query should return a single row with a single column (which you can call 'Average Rating') that represents the average rating of movies in the specified genre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [\n",
    "    {'Title': 'Jurassic World', 'Genre': 'Action', 'Year': 2015, 'Runtime': 124, 'Rating': 7.0},\n",
    "    {'Title': 'Inside Out', 'Genre': 'Animation', 'Year': 2015, 'Runtime': 95, 'Rating': 8.2},\n",
    "    {'Title': 'Toy Story 3', 'Genre': 'Animation', 'Year': 2010, 'Runtime': 103, 'Rating': 8.3},\n",
    "    {'Title': 'John Wick', 'Genre': 'Action', 'Year': 2014, 'Runtime': 101, 'Rating': 7.2},\n",
    "    {'Title': 'The Circle', 'Genre': 'Thriller', 'Year': 2017, 'Runtime': 110, 'Rating': 5.3},\n",
    "    {'Title': 'Manchester by the Sea', 'Genre': 'Drama', 'Year': 2016, 'Runtime': 137, 'Rating': 7.9},\n",
    "    {'Title': 'The Avengers', 'Genre': 'Action', 'Year': 2012, 'Runtime': 143, 'Rating': 8.1},\n",
    "    {'Title': 'Frozen', 'Genre': 'Animation', 'Year': 2013, 'Runtime': 102, 'Rating': 7.5},\n",
    "    {'Title': 'The Shape of Water', 'Genre': 'Fantasy', 'Year': 2017, 'Runtime': 123, 'Rating': 7.4},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_ratings=[]\n",
    "def average_by_genre(dictionary, genre):\n",
    "    for movie in dictionary:\n",
    "        if movie['Genre'] == genre:\n",
    "            genre_ratings.append(movie['Rating'])\n",
    "    return(round(sum(genre_ratings) / len(genre_ratings),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_by_genre(movies, 'Fantasy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in ['Action', 'Animation', 'Drama', 'Fantasy', 'Thriller']:\n",
    "    print(f\"The average rating of {genre} movies is {average_by_genre(movies, genre)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I did this in SQL on a table called Movies, I would use the following query:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    SELECT Genre, AVG(Rating) AS Avg_Rating, COUNT(*) AS Num_Ratings\n",
    "\n",
    "    FROM Movies\n",
    "\n",
    "    GROUP BY Genre\n",
    "\n",
    "    ORDER BY Avg_Rating DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are tasked with implementing a MovieDatabase class. The class should be initialized with a list of movies, where each movie is a dictionary with the following key-value pairs:\n",
    "\n",
    "- 'Title': The title of the movie (string).\n",
    "- 'Genre': The genre of the movie (string).\n",
    "- 'Year': The year the movie was released (integer).\n",
    "- 'Runtime': The length of the movie in minutes (integer).\n",
    "- 'Rating': The average user rating out of 10 (float).\n",
    "The MovieDatabase class should have a method average_rating_by_genre(self, genre: str) -> float: which returns the average rating of movies in the specified genre.\n",
    "\n",
    "### Libraries Needed\n",
    "\n",
    "- Python: None\n",
    "### Inputs\n",
    "\n",
    "The MovieDatabase class should be initialized with a movies: List[dict] argument, where movies is a list of dictionaries where each dictionary represents a movie with the key-value pairs described above.\n",
    "\n",
    "The average_rating_by_genre method should take in a single argument:\n",
    "\n",
    "- genre: a string representing the genre of the movies for which you want to calculate the average rating.\n",
    "Expected Outputs\n",
    "\n",
    "The average_rating_by_genre method should return a float representing the average rating of movies in the input genre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Movie:\n",
    "    def __init__(self, dictionary):\n",
    "        self.title = dictionary['Title']\n",
    "        self.genre = dictionary['Genre']\n",
    "        self.year = dictionary['Year']\n",
    "        self.runtime = dictionary['Runtime']\n",
    "        self.rating = dictionary['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie2 = Movie(movies[2])\n",
    "movie2.genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_as_objects = []\n",
    "\n",
    "for i in movies:\n",
    "    movies_as_objects.append(Movie(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_as_objects[0].rating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDatabase:\n",
    "    def __init__(self, movies: List[dict]):\n",
    "        self.movies = movies\n",
    "\n",
    "    def average_rating_by_genre(self, genre: str) -> float:\n",
    "        genre_movies = [movie for movie in self.movies if movie['Genre'] == genre]\n",
    "        average_rating = sum(movie['Rating'] for movie in genre_movies) / len(genre_movies)\n",
    "        return average_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took a different approach than what I ended up making, as it created a more comprehensive class that could be used to do more than just find the average rating by genre. I think this is a good approach. I also like how the class is initialized with a list of dictionaries, which is the same format as the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "You are given a small sample of a larger dataset, represented as a string that can be read into a pandas DataFrame using the `pd.read_clipboard()` function. The dataset represents sales data for a retail store and includes four columns: 'Product', 'Date', 'Sales', and 'Profit'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Your task is to:\n",
    "\n",
    "1. Read the data into a DataFrame.\n",
    "2. Convert the 'Date' column to datetime type.\n",
    "3. Replace any non-numeric characters in the 'Profit' column, then convert it to a numeric type.\n",
    "4. Calculate the total sales and profit for each product, and store the result in a new DataFrame.\n",
    "\n",
    "### Libraries Needed:\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "\n",
    "### Inputs:\n",
    "\n",
    "- A string representing the dataset.\n",
    "\n",
    "### Expected Outputs:\n",
    "\n",
    "- A DataFrame representing the cleaned dataset.\n",
    "- A DataFrame representing the total sales and profit for each product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading the data\n",
    "data = \"\"\"\n",
    "Product\tDate\tSales\tProfit\n",
    "Printer\t2022-05-17\t12\t$100\n",
    "Laptop\t2022-05-18\t10\t$150\n",
    "Printer\t2022-05-19\t8\t$75\n",
    "Monitor\t2022-05-20\t15\t$120\n",
    "Laptop\t2022-05-21\t7\t$100\n",
    "\"\"\"\n",
    "df = pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date = df.Date.astype('datetime64[ns]')\n",
    "\n",
    "df['Profit'] = df['Profit'].str.replace('$','').astype('int')\n",
    "df['Sales'] = df['Sales'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Sales: ${df.Sales.sum()}\")\n",
    "print(f\"Total Profit: ${df.Profit.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "Given a string of characters, write a function that calculates the frequency of each character in the string. Additionally, the function should return the character with the maximum frequency and the character with the minimum frequency.\n",
    "\n",
    "The function signature should be `def char_frequency(string: str) -> dict, str, str:`. The function should return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_characters(s):\n",
    "    split_string = s.split()\n",
    "    character_frequency = {}\n",
    "    for character in split_string:\n",
    "        if character in character_frequency:\n",
    "            character_frequency[character] += 1\n",
    "        else:\n",
    "            character_frequency[character] = 1\n",
    "    return character_frequency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_characters(\"I am learning data science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_characters(s):\n",
    "    split_string = s.split()\n",
    "    character_frequency = {}\n",
    "    for word in split_string:\n",
    "        for character in word:\n",
    "            if character in character_frequency:\n",
    "                character_frequency[character] += 1\n",
    "            else:\n",
    "                character_frequency[character] = 1\n",
    "    return character_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_characters(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_freqs = frequency_characters(\"Honolulu\")\n",
    "\n",
    "# get the most frequent character, the number of times it occurs, and any other characters that occur the same number of times\n",
    "max_freq = max(character_freqs.values())\n",
    "most_frequent_characters = [k for k, v in character_freqs.items() if v == max_freq]\n",
    "print(most_frequent_characters, max_freq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "You are given a list of dictionaries representing student grades for different subjects. Each dictionary includes the student's name and their grades for math, science, and english. Here's an example:\n",
    "```python\n",
    "grades = grades = [\n",
    "    {\"name\": \"Alice\", \"math\": 85, \"science\": 92, \"english\": 88},\n",
    "    {\"name\": \"Bob\", \"math\": 90, \"science\": 87, \"english\": 95},\n",
    "    {\"name\": \"Charlie\", \"math\": 82, \"science\": 89, \"english\": 91},\n",
    "    {\"name\": \"David\", \"math\": 78, \"science\": 76, \"english\": 84},\n",
    "    {\"name\": \"Eve\", \"math\": 92, \"science\": 90, \"english\": 93},\n",
    "    {\"name\": \"Frank\", \"math\": 89, \"science\": 92, \"english\": 87},\n",
    "    {\"name\": \"Grace\", \"math\": 91, \"science\": 88, \"english\": 93},\n",
    "    {\"name\": \"Henry\", \"math\": 86, \"science\": 85, \"english\": 90},\n",
    "    {\"name\": \"Ivy\", \"math\": 93, \"science\": 91, \"english\": 92},\n",
    "    {\"name\": \"Jack\", \"math\": 88, \"science\": 86, \"english\": 89},\n",
    "    {\"name\": \"Kate\", \"math\": 90, \"science\": 93, \"english\": 87},\n",
    "    {\"name\": \"Liam\", \"math\": 92, \"science\": 90, \"english\": 88},\n",
    "    {\"name\": \"Mia\", \"math\": 84, \"science\": 87, \"english\": 91},\n",
    "    {\"name\": \"Noah\", \"math\": 91, \"science\": 82, \"english\": 89},\n",
    "    {\"name\": \"Olivia\", \"math\": 89, \"science\": 88, \"english\": 90},\n",
    "    {\"name\": \"Patrick\", \"math\": 87, \"science\": 91, \"english\": 88},\n",
    "    {\"name\": \"Quinn\", \"math\": 86, \"science\": 90, \"english\": 87},\n",
    "    {\"name\": \"Ryan\", \"math\": 92, \"science\": 89, \"english\": 92},\n",
    "    {\"name\": \"Sara\", \"math\": 88, \"science\": 87, \"english\": 90},\n",
    "    {\"name\": \"Thomas\", \"math\": 90, \"science\": 88, \"english\": 89}\n",
    "]\n",
    "\n",
    "```\n",
    "#### Your task is to write a function that:\n",
    "\n",
    "Calculates the average grade for each student across all subjects, and adds this to the student's dictionary under the key \"average\".\n",
    "Returns a list of all students who have an average grade of 90 or higher. The list should contain only the names of the students, not their entire dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = grades = [\n",
    "    {\"name\": \"Alice\", \"math\": 85, \"science\": 92, \"english\": 88},\n",
    "    {\"name\": \"Bob\", \"math\": 90, \"science\": 87, \"english\": 95},\n",
    "    {\"name\": \"Charlie\", \"math\": 82, \"science\": 89, \"english\": 91},\n",
    "    {\"name\": \"David\", \"math\": 78, \"science\": 76, \"english\": 84},\n",
    "    {\"name\": \"Eve\", \"math\": 92, \"science\": 90, \"english\": 93},\n",
    "    {\"name\": \"Frank\", \"math\": 89, \"science\": 92, \"english\": 87},\n",
    "    {\"name\": \"Grace\", \"math\": 91, \"science\": 88, \"english\": 93},\n",
    "    {\"name\": \"Henry\", \"math\": 86, \"science\": 85, \"english\": 90},\n",
    "    {\"name\": \"Ivy\", \"math\": 93, \"science\": 91, \"english\": 92},\n",
    "    {\"name\": \"Jack\", \"math\": 88, \"science\": 86, \"english\": 89},\n",
    "    {\"name\": \"Kate\", \"math\": 90, \"science\": 93, \"english\": 87},\n",
    "    {\"name\": \"Liam\", \"math\": 92, \"science\": 90, \"english\": 88},\n",
    "    {\"name\": \"Mia\", \"math\": 84, \"science\": 87, \"english\": 91},\n",
    "    {\"name\": \"Noah\", \"math\": 91, \"science\": 82, \"english\": 89},\n",
    "    {\"name\": \"Olivia\", \"math\": 89, \"science\": 88, \"english\": 90},\n",
    "    {\"name\": \"Patrick\", \"math\": 87, \"science\": 91, \"english\": 88},\n",
    "    {\"name\": \"Quinn\", \"math\": 86, \"science\": 90, \"english\": 87},\n",
    "    {\"name\": \"Ryan\", \"math\": 92, \"science\": 89, \"english\": 92},\n",
    "    {\"name\": \"Sara\", \"math\": 88, \"science\": 87, \"english\": 90},\n",
    "    {\"name\": \"Thomas\", \"math\": 90, \"science\": 88, \"english\": 89}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_students(dataset):\n",
    "    studs = []\n",
    "    for student in dataset:\n",
    "        student['average'] = round((student['math'] + student['science'] + student['english']) / 3, 2)\n",
    "        if student['average'] > 90:\n",
    "            studs.append(student['name'])\n",
    "    return studs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_students = top_students(grades)\n",
    "top_students"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If I want to do this with Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student:\n",
    "    def __init__(self, name, math_grade, science_grade, english_grade):\n",
    "        self.name = name\n",
    "        self.math_grade = math_grade\n",
    "        self.science_grade = science_grade\n",
    "        self.english_grade = english_grade\n",
    "\n",
    "# Create instances of the Student class for the given students\n",
    "students = [\n",
    "    Student(\"Alice\", 85, 92, 88),\n",
    "    Student(\"Bob\", 90, 87, 95),\n",
    "    Student(\"Charlie\", 82, 89, 96),\n",
    "    Student(\"David\", 78, 76, 84),\n",
    "    Student(\"Eve\", 92, 90, 93)\n",
    "]\n",
    "\n",
    "# Add 20 additional students\n",
    "students.append(Student(\"Frank\", 89, 92, 87))\n",
    "students.append(Student(\"Grace\", 91, 88, 93))\n",
    "students.append(Student(\"Henry\", 86, 85, 90))\n",
    "students.append(Student(\"Ivy\", 93, 91, 92))\n",
    "students.append(Student(\"Jack\", 88, 86, 89))\n",
    "students.append(Student(\"Kate\", 90, 93, 87))\n",
    "students.append(Student(\"Liam\", 92, 90, 88))\n",
    "students.append(Student(\"Mia\", 84, 87, 91))\n",
    "students.append(Student(\"Noah\", 91, 82, 89))\n",
    "students.append(Student(\"Olivia\", 89, 88, 90))\n",
    "students.append(Student(\"Patrick\", 87, 91, 88))\n",
    "students.append(Student(\"Quinn\", 86, 90, 87))\n",
    "students.append(Student(\"Ryan\", 92, 89, 92))\n",
    "students.append(Student(\"Sara\", 88, 87, 90))\n",
    "students.append(Student(\"Thomas\", 90, 88, 89))\n",
    "\n",
    "# Print the list of students\n",
    "for student in students:\n",
    "    print(f\"Name: {student.name}, Math: {student.math_grade}, Science: {student.science_grade}, English: {student.english_grade}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_studs(students):\n",
    "    studs = []\n",
    "    for student in students:\n",
    "        # Use list comprehensions to find average grade across all subjects. append studs with names of students' whose average grade is greater than 90\n",
    "        if sum([student.math_grade, student.science_grade, student.english_grade]) / 3 > 90:\n",
    "            studs.append(student.name)\n",
    "    return studs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_studs(students)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a dataset that represents the scores of a series of data science quizzes. However, you suspect that some of these scores are incorrect due to system errors. You want to clean this data by removing the outliers using the Z-score method and then calculate some basic statistics about the cleaned data.\n",
    "\n",
    "Write a Python function that takes a Pandas DataFrame and a column name. The function should:\n",
    "\n",
    "1. Calculate the Z-score for each score in the specified column of the DataFrame.\n",
    "2. Consider scores to be outliers if their Z-scores are greater than 3 or less than -3.\n",
    "3. Remove the outliers from the DataFrame.\n",
    "4. Calculate and print the mean, median, and standard deviation of the cleaned scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_ids = ['q1', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9', 'q10', 'q11', 'q12']\n",
    "\n",
    "# Generate random scores between 0 and 100\n",
    "scores = np.random.uniform(0, 100, 88)\n",
    "\n",
    "# Create a DataFrame with 100 rows\n",
    "df = pd.DataFrame({'quiz_id': quiz_ids + ['q' + str(i) for i in range(13, 101)],\n",
    "                   'score': list(scores) + list(np.random.uniform(0, 100, 12))})\n",
    "\n",
    "# Display the extended DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores['z_score'] = (quiz_scores['score'] - quiz_scores['score'].mean()) / quiz_scores['score'].std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = (x - μ) / σ\n",
    "\n",
    "\n",
    "<u>​Where:</u>\n",
    "\n",
    "- z is the z-score\n",
    "- x is the observed value,\n",
    "- μ is the mean of the population, and\n",
    "- σ is the standard deviation of the population.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores['Outlier'] = False\n",
    "quiz_scores.loc[quiz_scores['z_score'].abs() > 3, 'score']['Outlier'] = True\n",
    "quiz_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores.loc[quiz_scores['Outlier'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores.drop(quiz_scores.loc[quiz_scores['Outlier'] == True].index, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No rows were outliers, but this is how it would be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_scores_mean = quiz_scores['score'].mean().round(2)\n",
    "quiz_scores_median = quiz_scores['score'].median().round(2)\n",
    "quiz_scores_std = quiz_scores['score'].std().round(2)\n",
    "\n",
    "print(f\"quiz score mean = {quiz_scores_mean}\")\n",
    "print(f\"quiz score median = {quiz_scores_median}\")\n",
    "print(f\"quiz score standard deviation = {quiz_scores_std}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "\n",
    "Imagine you have a database table named \"sales\" that stores sales data for an ecommerce company. The \"sales\" table has the following columns:\n",
    "\n",
    "- order_id (integer): A unique identifier for each order.\n",
    "- product_id (integer): A unique identifier for each product.\n",
    "- quantity (integer): The quantity of the product that was sold in the order.\n",
    "- sale_date (date): The date of the sale.\n",
    "\n",
    "Your task is to write a SQL query to fetch data that will be used to calculate the average quantity sold per product per month. \n",
    "\n",
    "Additionally, implement a function in Python using the sqlite3 library that takes the SQL query as a string and a sqlite3 connection object, executes the query, fetches the results, and then calculates and prints the average quantity sold per product per month based on the fetched data.\n",
    "\n",
    "# Libraries Needed: sqlite3, pandas\n",
    "\n",
    "# Inputs: \n",
    "\n",
    "- A string that contains the SQL query.\n",
    "- A sqlite3 connection object.\n",
    "\n",
    "Example in Python code:\n",
    "\n",
    "```python\n",
    "query = \"\"\"\n",
    "SELECT product_id, strftime('%Y-%m', sale_date) as month, SUM(quantity) as total_quantity\n",
    "FROM sales\n",
    "GROUP BY product_id, month\n",
    "\"\"\"\n",
    "\n",
    "def avg_quantity_per_product_per_month(query, conn):\n",
    "    # your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Outputs:\n",
    "\n",
    "Your function should print the average quantity sold per product per month. This can be done by grouping the fetched data by product and calculating the average quantity sold per month for each product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection object\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Define a DataFrame to populate the sales table\n",
    "data = {\n",
    "    'order_id': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'product_id': [101, 102, 103, 101, 102, 103, 101, 103],\n",
    "    'quantity': [2, 1, 3, 5, 2, 1, 4, 3],\n",
    "    'sale_date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-02-01', '2023-02-02', '2023-03-01', '2023-03-02', '2023-03-03']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the data to the sales table\n",
    "df.to_sql('sales', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT product_id, strftime('%Y-%m', sale_date) as month, SUM(quantity) as total_quantity\n",
    "FROM sales\n",
    "GROUP BY product_id, month\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run query on the database\n",
    "monthly_sales = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_quantity_per_product_per_month(query, conn):\n",
    "    monthly_sales = pd.read_sql(query, conn)\n",
    "    monthly_sales['avg_quantity'] = monthly_sales['total_quantity'].mean()\n",
    "    return monthly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better approach here is to use groupby\n",
    "\n",
    "def avg_quantity_per_product_per_month(query, conn):\n",
    "    dataframe = pd.read_sql(query, conn)\n",
    "    grouped_dataframe = dataframe.groupby(\"product_id\")\n",
    "    average_quantity = grouped_dataframe['total_quantity'].mean()\n",
    "    print(average_quantity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "\n",
    "You are working on a Natural Language Processing (NLP) project where you need to extract some features from text data. You have a list of sentences and you are interested in the number of digits that occur in each sentence.\n",
    "\n",
    "Write a Python function named `count_digits` that takes a list of strings (sentences) as input and returns a list of integers representing the number of digits in each sentence.\n",
    "\n",
    "# Libraries Needed: re (Regular expressions)\n",
    "\n",
    "# Inputs:\n",
    "\n",
    "A list of strings.\n",
    "\n",
    "Example in Python code:\n",
    "\n",
    "```python\n",
    "sentences = [\n",
    "    \"I have 2 dogs and 1 cat.\",\n",
    "    \"In 2022, the population of the world is estimated to be over 7.9 billion.\",\n",
    "    \"I was born on 12/12/2000.\"\n",
    "]\n",
    "\n",
    "counts = count_digits(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I have 2 dogs and 1 cat.\",\n",
    "    \"In 2022, the population of the world is estimated to be over 7.9 billion.\",\n",
    "    \"I was born on 12/12/2000.\",\n",
    "    \"In 1492, Columbus sailed the ocean blue.\",\n",
    "    \"The number 7 is considered lucky in many cultures.\",\n",
    "    \"There are 12 months, 52 weeks, and 365 days in a year.\",\n",
    "    \"Test without digits\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_digits(sentences):\n",
    "    sentences_counts = []\n",
    "    for sentence in sentences:\n",
    "        digit_counter = 0\n",
    "        for word in sentence.split():\n",
    "            for character in word:\n",
    "                if character.isdigit():\n",
    "                    digit_counter += 1\n",
    "        sentences_counts.append(digit_counter)\n",
    "    return sentences_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_digits(sentences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "\n",
    "You are provided with a dataset that includes stock prices for a particular company, and you are interested in visualizing the stock's closing price over time. \n",
    "\n",
    "The stock data is provided as a CSV string, where each row represents one day of trading. Each row includes the date, opening price, high price, low price, and closing price.\n",
    "\n",
    "Your task is to:\n",
    "1. Parse the CSV string into a pandas DataFrame.\n",
    "2. Convert the 'Date' column into a datetime data type.\n",
    "3. Set the 'Date' column as the index of the DataFrame.\n",
    "4. Plot a line graph of the closing prices over time.\n",
    "\n",
    "Here's the CSV data:\n",
    "\n",
    "```csv\n",
    "\"Date,Open,High,Low,Close\n",
    "2022-01-03,140.11,141.52,139.67,141.12\n",
    "2022-01-04,141.50,141.91,140.41,140.91\n",
    "2022-01-05,140.40,141.68,140.26,141.20\n",
    "2022-01-06,141.20,142.15,140.13,140.13\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = pd.read_clipboard(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick['Date'] = tick['Date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.line(tick, x='Date', y='Close', title='Stock Price')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "\n",
    "You are working as a Data Scientist at an e-commerce company and you have the historical transaction data for customers. The company wants to understand the behavior of the customers based on their purchasing frequency and amount spent.\n",
    "\n",
    "Given a dataset of transaction records, where each record includes a customer ID, transaction date, and transaction amount, you need to calculate the following for each customer:\n",
    "- The total amount spent,\n",
    "- The total number of transactions,\n",
    "- The average transaction amount,\n",
    "- The frequency of transactions (defined as the total number of transactions divided by the number of unique days on which transactions occurred).\n",
    "\n",
    "Finally, perform a k-means clustering (with k=3) on the calculated features to segment the customers.\n",
    "\n",
    "The input transaction data is provided as a CSV string as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Copy the entire CSV data (including headers) to your clipboard before running this code\n",
    "# Original CSV data\n",
    "data = \"\"\"Customer_ID,Transaction_Date,Transaction_Amount\n",
    "C001,2022-01-01,100.50\n",
    "C002,2022-01-01,200.00\n",
    "C001,2022-01-02,150.00\n",
    "C002,2022-01-03,300.00\n",
    "C001,2022-02-01,200.00\n",
    "C002,2022-02-01,150.00\n",
    "C001,2022-03-01,300.00\n",
    "C002,2022-03-02,400.00\n",
    "C001,2022-04-01,180.50\n",
    "C002,2022-04-02,250.00\n",
    "C003,2022-04-03,320.00\n",
    "C001,2022-05-01,210.00\n",
    "C002,2022-05-02,180.00\n",
    "C003,2022-05-03,370.00\n",
    "C001,2022-06-01,220.00\n",
    "C002,2022-06-02,190.00\n",
    "C003,2022-06-03,410.00\n",
    "C001,2022-07-01,230.00\n",
    "C002,2022-07-02,220.00\n",
    "C003,2022-07-03,450.00\n",
    "C001,2022-08-01,240.00\n",
    "C002,2022-08-02,210.00\n",
    "C003,2022-08-03,490.00\n",
    "C001,2022-09-01,250.00\n",
    "C002,2022-09-02,230.00\n",
    "C003,2022-09-03,530.00\n",
    "C001,2022-10-01,260.00\n",
    "C002,2022-10-02,250.00\n",
    "C003,2022-10-03,570.00\n",
    "C001,2022-11-01,270.00\n",
    "C002,2022-11-02,270.00\n",
    "C003,2022-11-03,610.00\n",
    "C001,2022-12-01,280.00\n",
    "C002,2022-12-02,290.00\n",
    "C003,2022-12-03,650.00\n",
    "C001,2023-01-01,290.00\n",
    "C002,2023-01-02,310.00\n",
    "C003,2023-01-03,690.00\n",
    "C001,2023-02-01,300.00\n",
    "C002,2023-02-02,330.00\n",
    "C003,2023-02-03,730.00\n",
    "C001,2023-03-01,310.00\n",
    "C002,2023-03-02,350.00\n",
    "C003,2023-03-03,770.00\n",
    "C001,2023-04-01,320.00\n",
    "C002,2023-04-02,370.00\n",
    "C003,2023-04-03,810.00\n",
    "C001,2023-05-01,330.00\n",
    "C002,2023-05-02,390.00\n",
    "C003,2023-05-03,850.00\n",
    "C001,2023-06-01,340.00\n",
    "C002,2023-06-02,410.00\n",
    "C003,2023-06-03,890.00\n",
    "C001,2023-07-01,350.00\n",
    "C002,2023-07-02,430.00\n",
    "C003,2023-07-03,930.00\n",
    "C001,2023-08-01,360.00\n",
    "C002,2023-08-02,450.00\n",
    "C003,2023-08-03,970.00\n",
    "C001,2023-09-01,370.00\n",
    "C002,2023-09-02,470.00\n",
    "C003,2023-09-03,1010.00\n",
    "C001,2023-10-01,380.00\n",
    "C002,2023-10-02,490.00\n",
    "C003,2023-10-03,1050.00\n",
    "C001,2023-11-01,390.00\n",
    "C002,2023-11-02,510.00\n",
    "C003,2023-11-03,1090.00\n",
    "C001,2023-12-01,400.00\n",
    "C002,2023-12-02,530.00\n",
    "C003,2023-12-03,1130.00\n",
    "\"\"\"\n",
    "\n",
    "# Additional data for new customers (C004 to C023)\n",
    "additional_data = \"\"\"\n",
    "C004,2022-01-01,120.50\n",
    "C005,2022-01-01,220.00\n",
    "C006,2022-01-02,130.00\n",
    "C004,2022-01-03,260.00\n",
    "C005,2022-02-01,240.00\n",
    "C006,2022-02-01,130.00\n",
    "C004,2022-03-01,330.00\n",
    "C005,2022-03-02,440.00\n",
    "C006,2022-04-01,280.50\n",
    "C007,2022-04-02,350.00\n",
    "C008,2022-04-03,420.00\n",
    "C004,2022-05-01,310.00\n",
    "C005,2022-05-02,280.00\n",
    "C006,2022-05-03,470.00\n",
    "C007,2022-06-01,320.00\n",
    "C008,2022-06-02,390.00\n",
    "C009,2022-06-03,510.00\n",
    "C004,2022-07-01,330.00\n",
    "C005,2022-07-02,320.00\n",
    "C006,2022-07-03,550.00\n",
    "C007,2022-08-01,340.00\n",
    "C008,2022-08-02,310.00\n",
    "C009,2022-08-03,590.00\n",
    "C010,2022-09-01,350.00\n",
    "C011,2022-09-02,430.00\n",
    "C012,2022-09-03,630.00\n",
    "C013,2022-10-01,360.00\n",
    "C014,2022-10-02,420.00\n",
    "C015,2022-10-03,570.00\n",
    "C010,2022-11-01,390.00\n",
    "C011,2022-11-02,520.00\n",
    "C012,2022-11-03,710.00\n",
    "C013,2022-12-01,400.00\n",
    "C014,2022-12-02,530.00\n",
    "C015,2022-12-03,770.00\n",
    "C010,2023-01-01,410.00\n",
    "C011,2023-01-02,540.00\n",
    "C012,2023-01-03,810.00\n",
    "C013,2023-02-01,430.00\n",
    "C014,2023-02-02,570.00\n",
    "C015,2023-02-03,870.00\n",
    "C010,2023-03-01,460.00\n",
    "C011,2023-03-02,610.00\n",
    "C012,2023-03-03,910.00\n",
    "C013,2023-04-01,490.00\n",
    "C014,2023-04-02,650.00\n",
    "C015,2023-04-03,970.00\n",
    "C010,2023-05-01,510.00\n",
    "C011,2023-05-02,690.00\n",
    "C012,2023-05-03,1010.00\n",
    "C013,2023-06-01,540.00\n",
    "C014,2023-06-02,720.00\n",
    "C015,2023-06-03,1050.00\n",
    "C010,2023-07-01,570.00\n",
    "C011,2023-07-02,750.00\n",
    "C012,2023-07-03,1090.00\n",
    "C013,2023-08-01,600.00\n",
    "C014,2023-08-02,790.00\n",
    "C015,2023-08-03,1130.00\n",
    "C010,2023-09-01,630.00\n",
    "C011,2023-09-02,830.00\n",
    "C012,2023-09-03,1170.00\n",
    "C013,2023-10-01,660.00\n",
    "C014,2023-10-02,870.00\n",
    "C015,2023-10-03,1210.00\n",
    "C010,2023-11-01,690.00\n",
    "C011,2023-11-02,910.00\n",
    "C012,2023-11-03,1250.00\n",
    "C013,2023-12-01,720.00\n",
    "C014,2023-12-02,950.00\n",
    "C015,2023-12-03,1290.00\n",
    "\"\"\"\n",
    "\n",
    "# Combine the original and additional data\n",
    "data += additional_data\n",
    "\n",
    "# Read the data using pandas\n",
    "cust = pd.read_csv(StringIO(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust.groupby('Customer_ID')['Transaction_Amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = cust.groupby('Customer_ID', as_index=False)[['Transaction_Amount']].sum()\n",
    "totals.columns = ['Customer_ID', 'Total_Transaction_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = cust.groupby('Customer_ID', as_index=False)[['Transaction_Amount']].mean()\n",
    "averages.columns = ['Customer_ID', 'Average_Transaction_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = cust.groupby('Customer_ID', as_index=False)[['Transaction_Amount']].count()\n",
    "counts.columns = ['Customer_ID', 'Count_Transaction_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_days = cust.groupby('Customer_ID', as_index=False)[['Transaction_Date']].nunique()   \n",
    "unique_days.columns = ['Customer_ID', 'Count_Unique_Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a df using merge on totals, averages, counts, and unique_days\n",
    "aggs = totals.merge(averages, on='Customer_ID')\n",
    "aggs = aggs.merge(counts, on='Customer_ID')\n",
    "aggs = aggs.merge(unique_days, on='Customer_ID')\n",
    "aggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs['Purchase_Frequency'] = aggs['Count_Transaction_Amount'] / aggs['Count_Unique_Days']\n",
    "aggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Means on the customers\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Make three clusters from the aggs dataframe. We want to batch customers, or \"Customer_IDs\" into three groups\n",
    "kmeans = KMeans(n_clusters=3).fit(aggs.drop('Customer_ID', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
